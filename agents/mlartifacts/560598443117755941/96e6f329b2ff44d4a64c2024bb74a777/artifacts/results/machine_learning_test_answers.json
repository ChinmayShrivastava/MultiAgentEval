{"columns":["question","hints","reason","answer","correct"],"data":[["Statement 1| Linear regression estimator has the smallest variance among all unbiased estimators. Statement 2| The coefficients \u03b1 assigned to the classifiers assembled by AdaBoost are always non-negative.","Task Statement:\n\nIdentify key properties of linear regression estimators and AdaBoost classifiers.\nKey Details:\n\n- Linear regression estimator has the smallest variance among all unbiased estimators.\n- The coefficients \u03b1 assigned to the classifiers assembled by AdaBoost are always non-negative.\nRelevant Formulas:\n\nN\/A\nSteps to Solve:\n\n1. Understand that the linear regression estimator has the smallest variance among all unbiased estimators.\n2. Recognize that the coefficients \u03b1 assigned to the classifiers assembled by AdaBoost are always non-negative.\nMissing Data:\n\nNone","1. The statement that the linear regression estimator has the smallest variance among all unbiased estimators is true.\n2. The statement that the coefficients \u03b1 assigned to the classifiers assembled by AdaBoost are always non-negative is also true.\n\nTherefore, the correct answer is option A: True, True.\n\n","A","D"],["Statement 1| RoBERTa pretrains on a corpus that is approximate 10x larger than the corpus BERT pretrained on. Statement 2| ResNeXts in 2018 usually used tanh activation functions.","Task Statement:\n\nDetermine the differences between RoBERTa and BERT pretraining corpus sizes and ResNeXt activation functions.\nKey Details:\n\n- RoBERTa pretrains on a corpus approximately 10 times larger than BERT's pretraining corpus.\n- ResNeXts in 2018 commonly used tanh activation functions.\nRelevant Formulas:\n\nN\/A\nSteps to Solve:\n\n1. Compare the pretraining corpus sizes of RoBERTa and BERT.\n2. Identify the activation function used in ResNeXts in 2018.\nMissing Data:\n\nNone","1. RoBERTa pretrains on a corpus that is approximately 10 times larger than the corpus BERT pretrains on. This statement is True.\n2. ResNeXts in 2018 usually used tanh activation functions. This statement is False as ResNeXts commonly use ReLU activation functions.\n\n","C","C"],["Statement 1| Support vector machines, like logistic regression models, give a probability distribution over the possible labels given an input example. Statement 2| We would expect the support vectors to remain the same in general as we move from a linear kernel to higher order polynomial kernels.","Task Statement:\n\nUnderstand the characteristics of support vector machines in relation to logistic regression models and kernel types.\nKey Details:\n\n- Support vector machines provide a probability distribution over possible labels for input examples.\n- Support vectors are expected to generally remain the same when transitioning from a linear kernel to higher order polynomial kernels.\nRelevant Formulas:\n\nN\/A\nSteps to Solve:\n\n1. Compare the probability distribution feature of support vector machines with logistic regression models.\n2. Analyze the consistency of support vectors when switching from linear to higher order polynomial kernels.\nMissing Data:\n\nNone","1. The first statement compares support vector machines to logistic regression models in terms of providing a probability distribution over possible labels for input examples. Logistic regression models also provide a probability distribution, so this statement is true.\n2. The second statement states that the support vectors are expected to generally remain the same when transitioning from a linear kernel to higher order polynomial kernels. This is true because support vectors are the data points that lie closest to the decision boundary and are crucial for classification, so they are likely to remain the same regardless of the kernel type.\n\n","D","B"],["A machine learning problem involves four attributes plus a class. The attributes have 3, 2, 2, and 2 possible values each. The class has 3 possible values. How many maximum possible different examples are there?","Task Statement:\n\nCalculate the maximum possible different examples in a machine learning problem with four attributes and a class.\nKey Details:\n\nNumber of values for attribute 1: 3\nNumber of values for attribute 2: 2\nNumber of values for attribute 3: 2\nNumber of values for attribute 4: 2\nNumber of values for the class: 3\nRelevant Formulas:\n\nTotal possible examples = (Number of values for attribute 1) * (Number of values for attribute 2) * (Number of values for attribute 3) * (Number of values for attribute 4) * (Number of values for the class)\nSteps to Solve:\n\nCalculate the total possible examples: Total possible examples = 3 * 2 * 2 * 2 * 3 = 72\nMissing Data:\n\nNone","To calculate the maximum possible different examples, we multiply the number of possible values for each attribute and the class. So, the total possible examples would be 3 * 2 * 2 * 2 * 3 = 72.\n","D","D"],["As of 2020, which architecture is best for classifying high-resolution images?","Task Statement:\n\nIdentify the best architecture for classifying high-resolution images as of 2020.\nKey Details:\n\nYear: 2020\nContext: Classification of high-resolution images\nRelevant Formulas:\n\nN\/A\nSteps to Solve:\n\nResearch and analyze the latest architectures used for image classification in 2020\nConsider factors such as accuracy, speed, and efficiency in handling high-resolution images\nDetermine the architecture that is most suitable for classifying high-resolution images based on the analysis\nMissing Data:\n\nSpecific architectures being compared\nPerformance metrics for each architecture","In 2020, convolutional neural networks (CNNs) are considered the best architecture for classifying high-resolution images. CNNs have been widely used in image classification tasks due to their ability to capture spatial hierarchies in images effectively. They are specifically designed to handle image data and have shown superior performance compared to other architectures like fully connected networks, graph networks, and RBF networks.\n\n","A","A"],["Statement 1| The log-likelihood of the data will always increase through successive iterations of the expectation maximation algorithm. Statement 2| One disadvantage of Q-learning is that it can only be used when the learner has prior knowledge of how its actions affect its environment.","Task Statement:\n\nIdentify key statements related to the log-likelihood in the expectation-maximization algorithm and the limitations of Q-learning.\nKey Details:\n\nStatement 1: Log-likelihood increases in successive iterations of EM algorithm\nStatement 2: Q-learning requires prior knowledge of action effects\nRelevant Formulas:\n\nN\/A\nSteps to Solve:\n\nUnderstand the concept of log-likelihood in the EM algorithm\nRecognize the limitation of Q-learning in terms of prior knowledge\nMissing Data:\n\nNone","Statement 1 is true because in the expectation-maximization algorithm, the log-likelihood of the data is guaranteed to increase or stay the same in each iteration.\nStatement 2 is false because Q-learning is a model-free reinforcement learning algorithm that does not require prior knowledge of the environment.\n\n","C","B"],["Let us say that we have computed the gradient of our cost function and stored it in a vector g. What is the cost of one gradient descent update given the gradient?","Task Statement:\n\nCalculate the cost of one gradient descent update given the gradient vector.\nKey Details:\n\nGradient vector (g)\nRelevant Formulas:\n\nCost of one gradient descent update = learning rate * norm(g)\nSteps to Solve:\n\nMultiply the learning rate by the norm of the gradient vector: Cost = learning rate * norm(g)\nMissing Data:\n\nLearning rate is not provided.","The cost of one gradient descent update is calculated by multiplying the learning rate by the norm of the gradient vector. The norm of the gradient vector represents the magnitude of the gradient, and the learning rate determines how big of a step we take in the direction of the gradient.\n\n","A","A"],["Statement 1| For a continuous random variable x and its probability distribution function p(x), it holds that 0 \u2264 p(x) \u2264 1 for all x. Statement 2| Decision tree is learned by minimizing information gain.","Task Statement:\n\nUnderstand the properties of a probability distribution function and the concept of information gain in decision tree learning.\nKey Details:\n\n- Probability distribution function (p(x)) for a continuous random variable (x)\n- Property: 0 \u2264 p(x) \u2264 1 for all x\n- Decision tree learning involves minimizing information gain\nRelevant Formulas:\n\nNone\nSteps to Solve:\n\n1. Understand the concept of a probability distribution function for a continuous random variable.\n2. Note the property that 0 \u2264 p(x) \u2264 1 for all x.\n3. Learn about decision tree learning and how it is done by minimizing information gain.\nMissing Data:\n\nNone","- Statement 1 is true because for a probability distribution function, the probability values must be between 0 and 1.\n- Statement 2 is false because decision trees are learned by maximizing information gain, not minimizing it.\n\n","C","B"],["Consider the Bayesian network given below. How many independent parameters are needed for this Bayesian Network H -> U <- P <- W?","Task Statement:\n\nDetermine the number of independent parameters required for the Bayesian Network H -> U <- P <- W.\nKey Details:\n\nNodes in the Bayesian Network: H, U, P, W\nRelationships: H -> U, U <- P, P <- W\nRelevant Formulas:\n\nNumber of independent parameters = \u03a0 (number of states of parents) * (number of states of node)\nSteps to Solve:\n\nCalculate the number of independent parameters for each node:\n- H: 2 parameters (H has no parents)\n- U: 2 * 2 = 4 parameters (2 states of H, 2 states of U)\n- P: 2 * 2 = 4 parameters (2 states of U, 2 states of P)\n- W: 2 * 2 = 4 parameters (2 states of P, 2 states of W)\nTotal independent parameters = 2 + 4 + 4 + 4 = 14 parameters\nMissing Data:\n\nNone","The number of independent parameters for each node in the Bayesian Network is calculated based on the number of states of its parents and the number of states of the node itself. \nFor node H, there are 2 parameters (H has no parents).\nFor node U, there are 4 parameters (2 states of H, 2 states of U).\nFor node P, there are 4 parameters (2 states of U, 2 states of P).\nFor node W, there are 4 parameters (2 states of P, 2 states of W).\nAdding these up, the total number of independent parameters required is 2 + 4 + 4 + 4 = 14 parameters.\n\n","B","C"],["As the number of training examples goes to infinity, your model trained on that data will have:","Key Details:\n\n- Number of training examples approaching infinity\nRelevant Formulas:\n\n- Asymptotic behavior of the model\nSteps to Solve:\n\n- The model will approach its true underlying distribution\n- The model will have lower variance and bias\n- The model will generalize better to unseen data\nMissing Data:\n\nNone","As the number of training examples approaches infinity, the model will approach its true underlying distribution. This means that the model will have lower variance and bias, leading to better generalization to unseen data.\n\n","A","A"],["Statement 1| The set of all rectangles in the 2D plane (which includes non axisaligned rectangles) can shatter a set of 5 points. Statement 2| The VC-dimension of k-Nearest Neighbour classifier when k = 1 is infinite.","Task Statement:\n\nDetermine the VC-dimension of the set of all rectangles in the 2D plane.\nKey Details:\n\n- The set of all rectangles in the 2D plane can shatter a set of 5 points.\n- The VC-dimension of k-Nearest Neighbour classifier when k = 1 is infinite.\nRelevant Formulas:\n\nVC-dimension is a measure of the capacity of a hypothesis set to shatter points.\nSteps to Solve:\n\nThe VC-dimension of a set of rectangles is at least 5, as it can shatter a set of 5 points.\nThe VC-dimension of the set of all rectangles in the 2D plane is 5 or greater.\nMissing Data:\n\nNone","- The first statement indicates that the set of all rectangles in the 2D plane can shatter a set of 5 points, implying that the VC-dimension of rectangles is at least 5.\n- The second statement states that the VC-dimension of k-Nearest Neighbour classifier when k = 1 is infinite.\n\nFrom the information provided, we know that the VC-dimension of rectangles is at least 5, and the VC-dimension of k-Nearest Neighbour classifier when k = 1 is infinite. Therefore, the correct answer should be True for the first statement and True for the second statement.\n\n","A","A"],["_ refers to a model that can neither model the training data nor generalize to new data.","Key Details:\n\n- The term \"overfitting\" refers to a model that can neither model the training data nor generalize to new data.\nRelevant Formulas:\n\nN\/A\nSteps to Solve:\n\nN\/A\nMissing Data:\n\nNone","The question is asking for a term that describes a model that can neither model the training data nor generalize to new data. This situation is known as overfitting, where the model fits the training data too closely and fails to generalize well to new data.\n\n","C","C"],["Statement 1| The F1 score can be especially useful for datasets with class high imbalance. Statement 2| The area under the ROC curve is one of the main metrics used to assess anomaly detectors.","Task Statement:\n\nIdentify key metrics used for evaluating classification models.\nKey Details:\n\n- F1 score is useful for datasets with class imbalance\n- Area under the ROC curve is a metric for assessing anomaly detectors\nRelevant Formulas:\n\nNone\nSteps to Solve:\n\nUnderstand the significance of F1 score for imbalanced datasets\nRecognize the importance of the area under the ROC curve for anomaly detection\nMissing Data:\n\nNone","- The F1 score is a metric that combines precision and recall, making it useful for datasets with class imbalance because it considers both false positives and false negatives.\n- The area under the ROC curve is a metric commonly used to evaluate the performance of binary classifiers, including anomaly detectors.\n\n","C","A"],["Statement 1| The back-propagation algorithm learns a globally optimal neural network with hidden layers. Statement 2| The VC dimension of a line should be at most 2, since I can find at least one case of 3 points that cannot be shattered by any line.","Task Statement:\n\nUnderstand the concepts of back-propagation algorithm and VC dimension in neural networks.\nKey Details:\n\n- Back-propagation algorithm learns a globally optimal neural network with hidden layers.\n- VC dimension of a line should be at most 2.\n- At least one case of 3 points cannot be shattered by any line.\nRelevant Formulas:\n\nNot applicable\nSteps to Solve:\n\n1. Understand the back-propagation algorithm for training neural networks.\n2. Learn about VC dimension and its implications on the shattering of points by lines.\nMissing Data:\n\nNone","- Statement 1 is True: The back-propagation algorithm is commonly used to train neural networks with hidden layers to find optimal weights that minimize the error.\n- Statement 2 is True: The VC dimension of a line is at most 2 because there exists at least one case of 3 points that cannot be separated by any line.\n\n","A","B"],["High entropy means that the partitions in classification are","Task Statement:\n\nIdentify the meaning of high entropy in classification partitions.\nKey Details:\n\nEntropy is a measure of disorder or uncertainty in a system.\nHigh entropy indicates a high level of disorder or uncertainty in classification partitions.\nRelevant Formulas:\n\nN\/A\nSteps to Solve:\n\nUnderstand that high entropy in classification partitions means there is a high level of disorder or uncertainty.\nMissing Data:\n\nNone","High entropy in classification partitions means that there is a high level of disorder or uncertainty. This implies that the partitions are not able to separate the data into distinct and clear categories, making them not pure.\n\n","B","B"],["Statement 1| Layer Normalization is used in the original ResNet paper, not Batch Normalization. Statement 2| DCGANs use self-attention to stabilize training.","Task Statement:\n\nIdentify the normalization technique used in the original ResNet paper and the stabilization method used in DCGANs.\nKey Details:\n\n- Original ResNet paper: Layer Normalization, not Batch Normalization\n- DCGANs stabilization method: Self-attention\nRelevant Formulas:\n\nN\/A\nSteps to Solve:\n\n1. Note that Layer Normalization was used in the original ResNet paper, not Batch Normalization.\n2. Recognize that DCGANs use self-attention to stabilize training.\nMissing Data:\n\nNone","- Statement 1 mentions that Layer Normalization is used in the original ResNet paper, not Batch Normalization.\n- Statement 2 states that DCGANs use self-attention to stabilize training.\n- Therefore, Statement 1 is True and Statement 2 is True.\n\n","A","B"],["In building a linear regression model for a particular data set, you observe the coefficient of one of the features having a relatively high negative value. This suggests that","Task Statement:\n\nInterpret the implication of a high negative coefficient in a linear regression model.\nKey Details:\n\n- Coefficient of a feature is high and negative\n- Linear regression model is being built for a specific data set\nRelevant Formulas:\n\nNone\nSteps to Solve:\n\n1. A high negative coefficient indicates a strong negative relationship between the feature and the target variable.\n2. The feature has a significant impact on predicting the target variable in the model.\n3. The feature contributes to decreasing the predicted value of the target variable as it increases.\nMissing Data:\n\nNone","A high negative coefficient in a linear regression model indicates a strong negative relationship between the feature and the target variable. This means that as the feature increases, the predicted value of the target variable decreases significantly. Therefore, the feature has a significant impact on the model and should not be ignored.\n\n","A","C"],["For a neural network, which one of these structural assumptions is the one that most affects the trade-off between underfitting (i.e. a high bias model) and overfitting (i.e. a high variance model):","Key Details:\n\nStructural assumptions of a neural network\nImpact on the trade-off between underfitting and overfitting\nRelevant Formulas:\n\nN\/A\nSteps to Solve:\n\nIdentify the structural assumption that most affects the trade-off between underfitting and overfitting in a neural network\nUnderstand how this assumption influences the bias-variance trade-off\nMissing Data:\n\nNone","The structural assumption that most affects the trade-off between underfitting and overfitting in a neural network is the number of hidden nodes. The number of hidden nodes directly impacts the complexity of the model, with too few hidden nodes leading to underfitting (high bias) and too many hidden nodes leading to overfitting (high variance).\n\n","A","A"],["For polynomial regression, which one of these structural assumptions is the one that most affects the trade-off between underfitting and overfitting:","Key Details:\n\n- Structural assumption in polynomial regression affecting the trade-off between underfitting and overfitting\nRelevant Context:\n\n- Polynomial regression involves fitting a polynomial function to the data\n- Underfitting occurs when the model is too simple to capture the underlying patterns in the data\n- Overfitting occurs when the model is too complex and fits the noise in the data\nRelevant Formulas:\n\nN\/A\nSteps to Solve:\n\nIdentify the structural assumption in polynomial regression that impacts the trade-off between underfitting and overfitting\nUnderstand how this assumption affects the model's ability to generalize to new data\nConsider the balance between model complexity and the bias-variance trade-off\nMissing Data:\n\nNone","The structural assumption in polynomial regression that most affects the trade-off between underfitting and overfitting is the polynomial degree. The degree of the polynomial determines the complexity of the model, with higher degrees allowing for more flexibility but also increasing the risk of overfitting.\n\n","A","A"],["Statement 1| As of 2020, some models attain greater than 98% accuracy on CIFAR-10. Statement 2| The original ResNets were not optimized with the Adam optimizer.","Task Statement:\n\nIdentify key information from the given statements.\nKey Details:\n\n- Some models achieve over 98% accuracy on CIFAR-10 as of 2020.\n- Original ResNets were not optimized with the Adam optimizer.\nRelevant Formulas:\n\nN\/A\nSteps to Solve:\n\n1. Note the high accuracy achieved on CIFAR-10 models in 2020.\n2. Acknowledge that the original ResNets did not use the Adam optimizer.\nMissing Data:\n\nNone","1. Statement 1 mentions that some models achieve greater than 98% accuracy on CIFAR-10 as of 2020, which implies that the statement is true.\n2. Statement 2 states that the original ResNets were not optimized with the Adam optimizer, which also implies that the statement is true.\n\nTherefore, the correct answer is option A: True, True.\n\n","A","A"],["The K-means algorithm:","Task Statement:\n\nUnderstand the output of the K-means algorithm.\nKey Details:\n\n- K-means algorithm is a clustering algorithm that partitions data into K clusters.\n- Output of the K-means algorithm includes the cluster centers and the assignment of data points to clusters.\nRelevant Formulas:\n\nN\/A\nSteps to Solve:\n\n1. Run the K-means algorithm on the given dataset.\n2. Obtain the cluster centers and the assignment of data points to clusters from the output.\n3. Analyze the results to understand the clustering performed by the algorithm.\nMissing Data:\n\nNone","The K-means algorithm is known for minimizing the within-class variance for a given number of clusters. It iteratively assigns data points to the nearest cluster center and updates the cluster centers to minimize the total within-cluster variance. This process continues until convergence.\n\n","C","C"],["Statement 1| VGGNets have convolutional kernels of smaller width and height than AlexNet's first-layer kernels. Statement 2| Data-dependent weight initialization procedures were introduced before Batch Normalization.","Task Statement:\n\nIdentify the key differences between VGGNets and AlexNet in terms of convolutional kernel sizes and the introduction of weight initialization procedures compared to Batch Normalization.\nKey Details:\n\n- VGGNets have convolutional kernels of smaller width and height than AlexNet's first-layer kernels.\n- Data-dependent weight initialization procedures were introduced before Batch Normalization.\nRelevant Formulas:\n\nN\/A\nSteps to Solve:\n\n1. Compare the sizes of convolutional kernels in VGGNets and AlexNet.\n2. Determine the sequence of introduction between data-dependent weight initialization procedures and Batch Normalization.\nMissing Data:\n\nNone","1. VGGNets have convolutional kernels of smaller width and height than AlexNet's first-layer kernels, which is a known difference between the two architectures.\n2. Data-dependent weight initialization procedures were introduced before Batch Normalization, indicating the sequence of introduction.\n\n","C","A"],["What is the rank of the following matrix? A = [[1, 1, 1], [1, 1, 1], [1, 1, 1]]","Task Statement:\n\nDetermine the rank of a given matrix.\nKey Details:\n\nMatrix A: [[1, 1, 1], [1, 1, 1], [1, 1, 1]]\nRelevant Formulas:\n\nRank of a matrix: The maximum number of linearly independent rows or columns in the matrix.\nSteps to Solve:\n\nIdentify the linearly independent rows or columns in the matrix A.\nCount the number of linearly independent rows or columns to determine the rank.\nMissing Data:\n\nNone","The matrix A = [[1, 1, 1], [1, 1, 1], [1, 1, 1]] has all rows identical, which means they are linearly dependent. Therefore, the rank of the matrix A is less than 3.\n\n","B","B"],["Statement 1| Density estimation (using say, the kernel density estimator) can be used to perform classification. Statement 2| The correspondence between logistic regression and Gaussian Naive Bayes (with identity class covariances) means that there is a one-to-one correspondence between the parameters of the two classifiers.","Task Statement:\n\nUnderstand the relationship between density estimation and classification, as well as the correspondence between logistic regression and Gaussian Naive Bayes.\nKey Details:\n\n- Density estimation, specifically using the kernel density estimator, can be utilized for classification.\n- Logistic regression and Gaussian Naive Bayes with identity class covariances have a one-to-one correspondence in terms of parameters.\nRelevant Formulas:\n\nN\/A\nSteps to Solve:\n\n1. Understand how density estimation, particularly using the kernel density estimator, can be applied to classification tasks.\n2. Explore the relationship between logistic regression and Gaussian Naive Bayes with identity class covariances to grasp the one-to-one correspondence between their parameters.\nMissing Data:\n\nNone","1. Density estimation, such as using the kernel density estimator, can indeed be used for classification tasks. This is because density estimation helps in estimating the probability density function of the data, which can aid in making classification decisions.\n2. The statement regarding the correspondence between logistic regression and Gaussian Naive Bayes with identity class covariances is true. When the class covariances in Gaussian Naive Bayes are assumed to be identity matrices, the model simplifies to logistic regression, establishing a one-to-one correspondence between the parameters of the two classifiers.\n\nTherefore, the correct answer is:\n","A","C"],["Suppose we would like to perform clustering on spatial data such as the geometrical locations of houses. We wish to produce clusters of many different sizes and shapes. Which of the following methods is the most appropriate?","Task Statement:\n\nIdentify the most appropriate method for clustering spatial data to produce clusters of various sizes and shapes.\nKey Details:\n\nSpatial data clustering\nDesire for clusters of different sizes and shapes\nRelevant Formulas:\n\nN\/A\nSteps to Solve:\n\nConsider methods that allow for flexibility in cluster sizes and shapes\nEvaluate methods that can handle spatial data effectively\nChoose the method that best fits the criteria\nMissing Data:\n\nSpecific clustering methods under consideration","In this scenario, where we want to produce clusters of various sizes and shapes for spatial data like the geometrical locations of houses, the most appropriate method would be Density-based clustering. Density-based clustering algorithms, such as DBSCAN, are suitable for handling spatial data and can create clusters of different sizes and shapes based on the density of data points. This method does not require specifying the number of clusters in advance and can adapt to the spatial distribution of the data.\n\n","B","B"],["Statement 1| In AdaBoost weights of the misclassified examples go up by the same multiplicative factor. Statement 2| In AdaBoost, weighted training error e_t of the tth weak classifier on training data with weights D_t tends to increase as a function of t.","Task Statement:\n\nUnderstand the behavior of weights and training error in AdaBoost.\nKey Details:\n\n1. AdaBoost weights of misclassified examples increase by the same multiplicative factor.\n2. Weighted training error e_t of the tth weak classifier on training data with weights D_t tends to increase as a function of t.\nRelevant Formulas:\n\nNot applicable\nSteps to Solve:\n\n1. Note that in AdaBoost, weights of misclassified examples increase by the same multiplicative factor.\n2. Understand that the weighted training error of the tth weak classifier tends to increase as a function of t in AdaBoost.\nMissing Data:\n\nNone","1. The first statement is true in AdaBoost, where weights of misclassified examples go up by the same multiplicative factor.\n2. The second statement is also true in AdaBoost, as the weighted training error of the tth weak classifier tends to increase as a function of t.\n\n","A","A"],["MLE estimates are often undesirable because","Key Details:\n\n- MLE stands for Maximum Likelihood Estimation\n- MLE estimates can be biased or inefficient in some cases\n- MLE estimates may not always have desirable properties like unbiasedness or efficiency\n- Other estimation methods may be preferred in certain situations\nRelevant Formulas:\n\nN\/A\nSteps to Solve:\n\n1. Understand the concept of Maximum Likelihood Estimation (MLE)\n2. Identify situations where MLE estimates may not be desirable\n3. Consider alternative estimation methods if MLE estimates are not suitable\nMissing Data:\n\nNone","1. Maximum Likelihood Estimation (MLE) aims to find the parameter values that maximize the likelihood function given the observed data.\n2. MLE estimates are often undesirable because they can be biased, meaning they systematically deviate from the true parameter values.\n3. MLE estimates may not always have desirable properties like unbiasedness or efficiency, making them less preferred in some cases.\n4. Given the options, option A is the most suitable as it highlights the issue of bias in MLE estimates.\n\n","C","B"],["Computational complexity of Gradient descent is,","Task Statement:\n\nCalculate the computational complexity of Gradient Descent.\nKey Details:\n\n- Gradient Descent algorithm\n- Number of iterations (n)\n- Learning rate (\u03b1)\n- Number of features (m)\n- Number of training examples (N)\nRelevant Formulas:\n\nComputational complexity of Gradient Descent = O(n * m * N)\nSteps to Solve:\n\n1. Identify the number of iterations (n), learning rate (\u03b1), number of features (m), and number of training examples (N).\n2. Substitute the values into the formula: Computational complexity = O(n * m * N)\n3. Calculate the result.\nMissing Data:\n\n- Specific values for the number of iterations, learning rate, number of features, and number of training examples.","The computational complexity of Gradient Descent is given by the formula O(n * m * N), where n is the number of iterations, m is the number of features, and N is the number of training examples. The complexity is not linear in D or N, as it depends on the number of iterations, features, and training examples.\n\n","D","C"],["Averaging the output of multiple decision trees helps _.","Task Statement:\n\nUnderstand the purpose of averaging the output of multiple decision trees.\nKey Details:\n\n- Averaging the output of multiple decision trees is a technique used in ensemble learning.\n- It helps to improve the predictive performance of the model by reducing overfitting and increasing generalization.\nRelevant Formulas:\n\nN\/A\nSteps to Solve:\n\n1. Train multiple decision trees on different subsets of the data.\n2. Obtain the output predictions from each decision tree.\n3. Average the output predictions to get the final prediction.\nMissing Data:\n\nNone","Averaging the output of multiple decision trees in ensemble learning helps to reduce overfitting and increase generalization by combining the predictions from different models. This process helps to smooth out individual errors and make more accurate predictions.\n\n","D","D"],["The model obtained by applying linear regression on the identified subset of features may differ from the model obtained at the end of the process of identifying the subset during","Task Statement:\n\nIdentify the reason for the potential difference in models obtained through linear regression.\nKey Details:\n\n- Linear regression applied on a subset of features\n- Potential difference in models obtained during the process of identifying the subset\nRelevant Formulas:\n\nN\/A\nSteps to Solve:\n\n1. Consider the impact of feature selection on model performance\n2. Evaluate the influence of different subsets of features on the final model\n3. Analyze the potential for overfitting or underfitting in the model selection process\nMissing Data:\n\nNone","When applying linear regression on a subset of features, the model obtained may differ from the final model obtained during the process of identifying the subset. This difference can be attributed to the different methods used for feature selection. Best-subset selection considers all possible combinations of features, forward stepwise selection adds one feature at a time based on performance, and forward stage wise selection adds features incrementally based on their impact. Therefore, the correct answer is D, as all of the mentioned methods can lead to differences in the final model obtained.\n\n","D","C"],["Neural networks:","Key Details:\n\n- Neural networks\n- Output from the neural network\n- Specific context or details about the neural network and its architecture\nRelevant Formulas:\n\n- Not applicable\nSteps to Solve:\n\n- Analyze the output from the neural network\n- Interpret the results based on the context or specific details provided\nMissing Data:\n\n- Specific details about the neural network architecture or input data may impact the interpretation of the output","Neural networks are known for their ability to approximate complex functions and optimize non-convex objective functions. They are not limited to convex objective functions. Additionally, neural networks can use a mix of different activation functions in their layers to introduce non-linearity and improve the model's performance.\n\n","C","C"],["Say the incidence of a disease D is about 5 cases per 100 people (i.e., P(D) = 0.05). Let Boolean random variable D mean a patient \u201chas disease D\u201d and let Boolean random variable TP stand for \"tests positive.\" Tests for disease D are known to be very accurate in the sense that the probability of testing positive when you have the disease is 0.99, and the probability of testing negative when you do not have the disease is 0.97. What is P(TP), the prior probability of testing positive.","Task Statement:\n\nCalculate the prior probability of testing positive for disease D.\nKey Details:\n\nP(D) = 0.05\nP(TP|D) = 0.99\nP(TP|\u00acD) = 0.03\nRelevant Formulas:\n\nP(TP) = P(TP|D) * P(D) + P(TP|\u00acD) * P(\u00acD)\nSteps to Solve:\n\nCalculate P(\u00acD) = 1 - P(D) = 1 - 0.05 = 0.95\nSubstitute the values into the formula: P(TP) = 0.99 * 0.05 + 0.03 * 0.95\nCalculate the result: P(TP) = 0.05\nMissing Data:\n\nNone","First, calculate P(\u00acD) which is 1 - P(D) = 1 - 0.05 = 0.95.\nThen, substitute the values into the formula: P(TP) = P(TP|D) * P(D) + P(TP|\u00acD) * P(\u00acD).\nCalculate the result: P(TP) = 0.99 * 0.05 + 0.03 * 0.95 = 0.05.\n\n","A","C"],["Statement 1| After mapped into feature space Q through a radial basis kernel function, 1-NN using unweighted Euclidean distance may be able to achieve better classification performance than in original space (though we can\u2019t guarantee this). Statement 2| The VC dimension of a Perceptron is smaller than the VC dimension of a simple linear SVM.","Key Details:\n\n- Mapping into feature space Q through a radial basis kernel function\n- 1-NN using unweighted Euclidean distance\n- Classification performance improvement in feature space Q compared to original space\n- VC dimension of Perceptron\n- VC dimension of simple linear SVM\nRelevant Formulas:\n\nNot applicable\nSteps to Solve:\n\n1. Apply radial basis kernel function to map into feature space Q\n2. Use 1-NN with unweighted Euclidean distance for classification\n3. Compare classification performance in feature space Q with original space\n4. Determine the VC dimension of Perceptron\n5. Determine the VC dimension of simple linear SVM\nMissing Data:\n\nNone","1. After mapping into feature space Q through a radial basis kernel function, the data is transformed into a higher-dimensional space where it may be easier to separate classes.\n2. 1-NN using unweighted Euclidean distance is a simple and effective classification algorithm that can work well in high-dimensional spaces.\n3. The statement suggests that the classification performance in feature space Q may be better than in the original space, although it is not guaranteed.\n4. The VC dimension of a Perceptron is smaller than the VC dimension of a simple linear SVM, as the Perceptron is a simpler linear classifier.\n\n","C","B"],["The disadvantage of Grid search is","Task Statement:\n\nIdentify the disadvantage of Grid search.\nKey Details:\n\nGrid search is a hyperparameter tuning technique in machine learning.\nIt exhaustively searches through a specified parameter grid to find the best model performance.\nRelevant Formulas:\n\nN\/A\nSteps to Solve:\n\nUnderstand that the disadvantage of Grid search is its computational complexity.\nIt can be time-consuming and resource-intensive, especially with large parameter grids.\nMissing Data:\n\nNone","The disadvantage of Grid search is its computational complexity, as it exhaustively searches through a specified parameter grid, which can be time-consuming and resource-intensive.\n\n","C","D"],["Predicting the amount of rainfall in a region based on various cues is a ______ problem.","Key Details:\n\nPredicting the amount of rainfall in a region\nBased on various cues\nRelevant Formulas:\n\nNone\nSteps to Solve:\n\nIdentify the cues that can help predict rainfall\nAnalyze historical data and patterns to make predictions\nConsider factors like temperature, humidity, wind patterns, and cloud cover\nUse statistical models or machine learning algorithms to make accurate predictions\nMissing Data:\n\nNone","In this scenario, predicting the amount of rainfall in a region based on various cues involves using historical data and patterns to make accurate predictions. This process falls under supervised learning, where the algorithm learns from labeled data to predict outcomes. Factors like temperature, humidity, wind patterns, and cloud cover can be used as cues to predict rainfall, making it a supervised learning problem.\n\n","A","A"],["Which of the following sentence is FALSE regarding regression?","Task Statement:\n\nIdentify the false statement regarding regression.\nKey Details:\n\n- Regression is a statistical method used to analyze the relationship between variables.\n- It can be used to predict the value of one variable based on the value of another variable.\n- Regression always implies causation between variables.\n- It can be linear or nonlinear depending on the relationship between variables.\nRelevant Formulas:\n\nN\/A\nSteps to Solve:\n\n1. Review each statement regarding regression.\n2. Identify the statement that does not accurately describe regression.\n3. Select the statement that is FALSE.\nMissing Data:\n\nNone","- Statement A is true because regression does relate inputs to outputs.\n- Statement B is true because regression is commonly used for prediction.\n- Statement C is true because regression can be used for interpretation.\n- Statement D is false because regression does not always discover causal relationships. It can show relationships between variables but does not imply causation.\n\n","D","D"],["Which one of the following is the main reason for pruning a Decision Tree?","Task Statement:\n\nIdentify the main reason for pruning a Decision Tree.\nKey Details:\n\n- Pruning helps prevent overfitting in Decision Trees.\n- It simplifies the model by removing unnecessary branches.\n- Pruning improves the generalization ability of the Decision Tree.\nRelevant Formulas:\n\nN\/A\nSteps to Solve:\n\nUnderstand that pruning is done to prevent overfitting in Decision Trees.\nRecognize that pruning simplifies the model by removing unnecessary branches.\nRealize that pruning improves the generalization ability of the Decision Tree.\nMissing Data:\n\nNone","Pruning a Decision Tree is primarily done to prevent overfitting by simplifying the model and improving its generalization ability. It helps remove unnecessary branches that may lead to overfitting on the training data.\n\n","D","D"],["Statement 1| The kernel density estimator is equivalent to performing kernel regression with the value Yi = 1\/n at each point Xi in the original data set. Statement 2| The depth of a learned decision tree can be larger than the number of training examples used to create the tree.","Task Statement:\n\nUnderstand the relationship between kernel density estimator and kernel regression, as well as the depth of a learned decision tree compared to the number of training examples.\nKey Details:\n\n- Kernel density estimator is equivalent to kernel regression with Yi = 1\/n at each point Xi in the original data set.\n- The depth of a learned decision tree can exceed the number of training examples used to create the tree.\nRelevant Formulas:\n\nN\/A\nSteps to Solve:\n\n1. Understand the concept of kernel density estimator and kernel regression.\n2. Recognize the relationship between Yi = 1\/n and the kernel density estimator.\n3. Understand the concept of decision tree depth and its relationship to the number of training examples.\n4. Compare the depth of a learned decision tree to the number of training examples.\nMissing Data:\n\nNone.","- The first statement states that the kernel density estimator is equivalent to performing kernel regression with Yi = 1\/n at each point Xi in the original data set, which is true.\n- The second statement mentions that the depth of a learned decision tree can be larger than the number of training examples used to create the tree, which is also true. Decision trees can grow deeper than the number of training examples due to the splitting process.\n\n","A","B"],["Suppose your model is overfitting. Which of the following is NOT a valid way to try and reduce the overfitting?","Task Statement:\n\nIdentify the invalid method to reduce overfitting in a model.\nKey Details:\n\n- Regularization techniques\n- Increasing the complexity of the model\n- Dropout in neural networks\n- Early stopping\nRelevant Formulas:\n\nN\/A\nSteps to Solve:\n\n- Evaluate each option and determine if it is a valid method to reduce overfitting.\n- Identify the option that is NOT a valid way to reduce overfitting.\nMissing Data:\n\nNone","- A. Increasing the amount of training data is a valid way to reduce overfitting as it can help the model generalize better.\n- B. Improving the optimization algorithm can also help in reducing overfitting by finding better minima.\n- C. Decreasing the model complexity is a valid way to reduce overfitting as simpler models are less likely to overfit.\n- D. Reducing the noise in the training data is a valid way to reduce overfitting as noisy data can lead to the model learning patterns that do not generalize well.\n\nTherefore, the option that is NOT a valid way to reduce overfitting is increasing the complexity of the model.\n\n","B","B"],["Statement 1| The softmax function is commonly used in mutliclass logistic regression. Statement 2| The temperature of a nonuniform softmax distribution affects its entropy.","Task Statement:\n\nUnderstand the relationship between the softmax function, multiclass logistic regression, and entropy in a nonuniform softmax distribution.\nKey Details:\n\n- Softmax function used in multiclass logistic regression\n- Temperature affects entropy in a nonuniform softmax distribution\nRelevant Formulas:\n\n- Softmax function formula\n- Entropy formula\nSteps to Solve:\n\n1. Understand the purpose of the softmax function in multiclass logistic regression.\n2. Explore how temperature impacts the entropy of a nonuniform softmax distribution.\nMissing Data:\n\nNone","1. The softmax function is commonly used in multiclass logistic regression because it converts raw scores into probabilities that sum up to 1, making it suitable for classification tasks.\n2. The temperature of a nonuniform softmax distribution affects its entropy because it controls the level of uncertainty or randomness in the distribution. A higher temperature leads to a more uniform distribution and higher entropy.\n\nTherefore, Statement 1 is True, and Statement 2 is True.\n\n","A","A"],["Which of the following is\/are true regarding an SVM?","Task Statement:\n\nIdentify the true statements regarding an SVM.\nKey Details:\n\n- SVM stands for Support Vector Machine.\n- SVM is a supervised machine learning algorithm used for classification and regression tasks.\n- SVM finds the optimal hyperplane that best separates the classes in the feature space.\n- SVM can handle both linear and non-linear data.\n- SVM aims to maximize the margin between the classes.\nRelevant Formulas:\n\nNone\nSteps to Solve:\n\n1. Understand the concept of SVM and its key characteristics.\n2. Evaluate each statement provided to determine its truthfulness based on the information about SVM.\n3. Identify the statement(s) that accurately describe SVM.\nMissing Data:\n\nNone","A. For two-dimensional data points, the separating hyperplane learned by a linear SVM will indeed be a straight line as SVM aims to find the optimal hyperplane for separation.\nB. In theory, a Gaussian kernel SVM can model complex separating hyperplanes as it can handle non-linear data through kernel tricks.\nC. For every kernel function used in an SVM, one cannot obtain an equivalent closed form basis expansion as some kernel functions are complex and non-linear.\nD. Overfitting in an SVM can be a function of the number of support vectors as having too many support vectors can lead to overfitting.\n\n","A","A"],["Which of the following is the joint probability of H, U, P, and W described by the given Bayesian Network H -> U <- P <- W? [note: as the product of the conditional probabilities]","Task Statement:\n\nCalculate the joint probability of H, U, P, and W in the given Bayesian Network.\nKey Details:\n\nBayesian Network: H -> U <- P <- W\nConditional Probabilities:\n- P(U|H) = 0.8\n- P(P|U) = 0.6\n- P(W|P) = 0.7\nRelevant Formulas:\n\nJoint Probability = P(H) * P(U|H) * P(P|U) * P(W|P)\nSteps to Solve:\n\nCalculate the joint probability using the conditional probabilities provided.\nJoint Probability = P(H) * 0.8 * 0.6 * 0.7\nMissing Data:\n\nMissing the prior probability P(H) which is needed to calculate the joint probability.","To calculate the joint probability of H, U, P, and W in the given Bayesian Network, we need to use the conditional probabilities provided. The joint probability formula is the product of the prior probability and the conditional probabilities along the network. Given the Bayesian Network structure and the conditional probabilities, we can calculate the joint probability step by step.\n\n","D","C"],["Statement 1| Since the VC dimension for an SVM with a Radial Base Kernel is infinite, such an SVM must be worse than an SVM with polynomial kernel which has a finite VC dimension. Statement 2| A two layer neural network with linear activation functions is essentially a weighted combination of linear separators, trained on a given dataset; the boosting algorithm built on linear separators also finds a combination of linear separators, therefore these two algorithms will give the same result.","Task Statement:\n\nAnalyze the implications of the VC dimension for SVM with Radial Base Kernel and SVM with polynomial kernel, as well as the relationship between a two-layer neural network with linear activation functions and boosting algorithm based on linear separators.\nKey Details:\n\n- VC dimension for SVM with Radial Base Kernel is infinite\n- VC dimension for SVM with polynomial kernel is finite\n- Two-layer neural network with linear activation functions is a weighted combination of linear separators\n- Boosting algorithm based on linear separators finds a combination of linear separators\nRelevant Formulas:\n\nN\/A\nSteps to Solve:\n\n1. Understand the concept of VC dimension and its implications on the complexity of the model\n2. Compare the implications of infinite VC dimension for SVM with Radial Base Kernel and finite VC dimension for SVM with polynomial kernel\n3. Analyze how a two-layer neural network with linear activation functions is related to a weighted combination of linear separators\n4. Consider how the boosting algorithm based on linear separators finds a combination of linear separators and its implications on the results\nMissing Data:\n\nNone","- Statement 1 is True because the VC dimension for an SVM with a Radial Base Kernel is infinite, indicating higher complexity compared to an SVM with a polynomial kernel which has a finite VC dimension.\n- Statement 2 is False because while a two-layer neural network with linear activation functions is a weighted combination of linear separators, the boosting algorithm based on linear separators may find a different combination of linear separators, leading to potentially different results.\n\n","C","B"],["Statement 1| The ID3 algorithm is guaranteed to find the optimal decision tree. Statement 2| Consider a continuous probability distribution with density f() that is nonzero everywhere. The probability of a value x is equal to f(x).","Task Statement:\n\nUnderstand the statements related to the ID3 algorithm and continuous probability distribution.\nKey Details:\n\n- Statement 1: ID3 algorithm guarantees finding the optimal decision tree.\n- Statement 2: Continuous probability distribution with density f() nonzero everywhere.\n- Probability of a value x is equal to f(x).\nRelevant Formulas:\n\nNone\nSteps to Solve:\n\n1. Understand the concept of the ID3 algorithm and its guarantee of finding the optimal decision tree.\n2. Analyze the characteristics of a continuous probability distribution with density f() nonzero everywhere.\n3. Recognize the relationship between the probability of a value x and f(x).\nMissing Data:\n\nNone","1. The ID3 algorithm is a heuristic algorithm used for decision tree learning, but it does not guarantee finding the optimal decision tree. It may find a locally optimal tree but not necessarily the best one.\n2. In a continuous probability distribution, the probability of a specific value x is represented by the density function f(x), but this does not mean that the probability of x is equal to f(x) for all x.\n\n","D","B"],["Given a Neural Net with N input nodes, no hidden layers, one output node, with Entropy Loss and Sigmoid Activation Functions, which of the following algorithms (with the proper hyper-parameters and initialization) can be used to find the global optimum?","Task Statement:\n\nIdentify the algorithm suitable for finding the global optimum in a Neural Net with specific characteristics.\nKey Details:\n\n- Neural Net configuration: N input nodes, no hidden layers, one output node\n- Loss function: Entropy Loss\n- Activation function: Sigmoid\nRelevant Formulas:\n\nN\/A\nSteps to Solve:\n\nIdentify algorithms suitable for training Neural Nets with the given configuration\nConsider algorithms that work well with Sigmoid activation and Entropy Loss\nChoose the algorithm with proper hyper-parameters and initialization for finding the global optimum\nMissing Data:\n\nSpecific algorithms and their hyper-parameters are not provided.","For a Neural Net with N input nodes, no hidden layers, one output node, using Sigmoid activation function and Entropy Loss, the suitable algorithm for finding the global optimum would be Batch Gradient Descent. This is because Batch Gradient Descent computes the gradient of the loss function with respect to the weights for the entire training dataset, which is beneficial for convergence in this scenario.\n\n","C","D"],["Adding more basis functions in a linear model, pick the most probably option:","Key Details:\n\n- Adding more basis functions in a linear model can lead to overfitting\n- Overfitting occurs when the model fits the training data too closely, capturing noise rather than the underlying pattern\n- Overfitting can result in poor generalization to new, unseen data\n- Therefore, the most probable option is that adding more basis functions in a linear model increases the risk of overfitting\nRelevant Formulas:\n\nN\/A\nSteps to Solve:\n\n1. Understand the concept of overfitting in machine learning models\n2. Recognize that adding more basis functions in a linear model can lead to overfitting\n3. Choose the most probable option based on the understanding of overfitting\nMissing Data:\n\nNone","Adding more basis functions in a linear model can lead to overfitting, where the model fits the training data too closely and captures noise rather than the underlying pattern. This can result in poor generalization to new, unseen data.\n\n","C","A"],["Consider the Bayesian network given below. How many independent parameters would we need if we made no assumptions about independence or conditional independence H -> U <- P <- W?","Task Statement:\n\nDetermine the number of independent parameters needed for the Bayesian network without assuming any independence or conditional independence.\nKey Details:\n\nNodes: H, U, P, W\nConnections: H -> U, U <- P, P <- W\nRelevant Formulas:\n\nNumber of independent parameters = \u03a3 (number of categories - 1) * (number of parents)\nSteps to Solve:\n\nCalculate the number of independent parameters for each node based on the number of categories and parents.\nSum up the independent parameters for all nodes to get the total number needed.\nMissing Data:\n\nNone","For each node, we need to consider the number of categories minus 1 multiplied by the number of parents. \n\nFor node H, it has 2 categories (True, False) and no parents, so it requires 1 independent parameter.\n\nFor node U, it has 2 categories and 1 parent (H), so it requires (2-1) * 1 = 1 independent parameter.\n\nFor node P, it has 2 categories and 1 parent (U), so it requires (2-1) * 1 = 1 independent parameter.\n\nFor node W, it has 2 categories and 1 parent (P), so it requires (2-1) * 1 = 1 independent parameter.\n\nAdding up all the independent parameters for each node, we get 1 + 1 + 1 + 1 = 4.\n\n","A","D"],["Another term for out-of-distribution detection is?","Task Statement:\n\nIdentify another term for out-of-distribution detection.\nKey Details:\n\n- Synonym for out-of-distribution detection\nRelevant Formulas:\n\nNone\nSteps to Solve:\n\nResearch or recall alternative terms for out-of-distribution detection.\nProvide the identified synonym for out-of-distribution detection.\nMissing Data:\n\nNone","Out-of-distribution detection refers to the task of identifying samples that do not belong to the training distribution. Anomaly detection is a common term used interchangeably with out-of-distribution detection as it involves identifying rare or unusual instances in a dataset.\n\n","A","A"],["Statement 1| We learn a classifier f by boosting weak learners h. The functional form of f\u2019s decision boundary is the same as h\u2019s, but with different parameters. (e.g., if h was a linear classifier, then f is also a linear classifier). Statement 2| Cross validation can be used to select the number of iterations in boosting; this procedure may help reduce overfitting.","Task Statement:\n\nUnderstand the relationship between boosting weak learners and the decision boundary of the classifier, as well as the role of cross-validation in selecting the number of iterations in boosting to prevent overfitting.\nKey Details:\n\n- Classifier f is learned by boosting weak learners h\n- Functional form of f's decision boundary is the same as h's, but with different parameters\n- Cross-validation can be used to select the number of iterations in boosting\n- Cross-validation helps reduce overfitting\nRelevant Formulas:\n\nN\/A\nSteps to Solve:\n\n1. Understand that boosting combines multiple weak learners to create a strong classifier f\n2. Note that the decision boundary of f has the same form as h, the weak learner, but with different parameters\n3. Recognize that cross-validation can be used to determine the optimal number of iterations in boosting\n4. Use cross-validation to prevent overfitting by selecting the appropriate number of iterations\nMissing Data:\n\nNone","- The first statement is true as boosting combines weak learners to create a strong classifier with the decision boundary having the same form as the weak learner but different parameters.\n- The second statement is also true as cross-validation can indeed be used to select the number of iterations in boosting, which can help prevent overfitting.\n\n","A","D"],["Statement 1| Highway networks were introduced after ResNets and eschew max pooling in favor of convolutions. Statement 2| DenseNets usually cost more memory than ResNets.","Task Statement:\n\nIdentify the characteristics of Highway networks and DenseNets compared to ResNets.\nKey Details:\n\n- Highway networks introduced after ResNets\n- Highway networks avoid max pooling in favor of convolutions\n- DenseNets typically require more memory than ResNets\nRelevant Formulas:\n\nN\/A\nSteps to Solve:\n\n1. Understand the differences between Highway networks and ResNets regarding max pooling and convolutions.\n2. Compare the memory usage of DenseNets and ResNets.\nMissing Data:\n\nNone","1. Statement 1 is True. Highway networks were introduced after ResNets and they do avoid max pooling in favor of convolutions.\n2. Statement 2 is True. DenseNets typically require more memory than ResNets.\n\n","A","D"],["If N is the number of instances in the training dataset, nearest neighbors has a classification run time of","Key Details:\n\nNumber of instances in the training dataset (N)\nClassification run time of nearest neighbors algorithm\nRelevant Formulas:\n\nNot applicable\nSteps to Solve:\n\nNo specific calculation needed, simply provide the classification run time for nearest neighbors algorithm based on the number of instances in the training dataset (N)\nMissing Data:\n\nNone","Nearest neighbors algorithm has a classification run time of O(N) where N is the number of instances in the training dataset. This is because for each new instance to be classified, the algorithm needs to calculate the distance to all N instances in the training dataset to find the nearest neighbors.\n\n","B","B"],["Statement 1| The original ResNets and Transformers are feedforward neural networks. Statement 2| The original Transformers use self-attention, but the original ResNet does not.","Task Statement:\n\nIdentify the characteristics of the original ResNets and Transformers.\nKey Details:\n\n- Original ResNets and Transformers are feedforward neural networks\n- Original Transformers use self-attention, while original ResNet does not\nRelevant Formulas:\n\nN\/A\nSteps to Solve:\n\n1. Understand that original ResNets and Transformers are feedforward neural networks.\n2. Note that original Transformers utilize self-attention, whereas original ResNet does not.\nMissing Data:\n\nNone","1. The original ResNets and Transformers are both feedforward neural networks.\n2. The original Transformers use self-attention, while the original ResNet does not.\n\n","C","A"],["Statement 1| RELUs are not monotonic, but sigmoids are monotonic. Statement 2| Neural networks trained with gradient descent with high probability converge to the global optimum.","Task Statement:\n\nUnderstand the properties of RELUs and sigmoids, as well as the convergence behavior of neural networks trained with gradient descent.\nKey Details:\n\n- RELUs are not monotonic functions.\n- Sigmoids are monotonic functions.\n- Neural networks trained with gradient descent have a high probability of converging to the global optimum.\nRelevant Formulas:\n\nNot applicable\nSteps to Solve:\n\n1. Understand the non-monotonic nature of RELUs and the monotonic nature of sigmoids.\n2. Recognize that neural networks trained with gradient descent tend to converge to the global optimum with high probability.\nMissing Data:\n\nNone","- Statement 1 states that RELUs are not monotonic, which is true because RELUs have regions where the output is constant, leading to non-monotonic behavior.\n- Statement 1 also states that sigmoids are monotonic, which is true because sigmoids are always increasing or always decreasing functions.\n- Statement 2 states that neural networks trained with gradient descent have a high probability of converging to the global optimum, which is generally true due to the nature of gradient descent optimization.\n\nTherefore, the correct answer is option A: True, True.\n\n","A","D"],["The numerical output of a sigmoid node in a neural network:","Task Statement:\n\nDetermine the numerical output of a sigmoid node in a neural network.\nKey Details:\n\nOutput of the sigmoid node\nRelevant Formulas:\n\nSigmoid function: f(x) = 1 \/ (1 + e^(-x))\nSteps to Solve:\n\nSubstitute the output value into the sigmoid function: f(output) = 1 \/ (1 + e^(-output))\nCalculate the numerical output of the sigmoid node.\nMissing Data:\n\nNone","The sigmoid function is defined as f(x) = 1 \/ (1 + e^(-x)), where x is the input value. The output of the sigmoid function is always bounded between 0 and 1 due to the nature of the function. As the input value approaches positive infinity, the output approaches 1, and as the input value approaches negative infinity, the output approaches 0. Therefore, the correct answer is C. Is bounded between 0 and 1.\n\n","C","C"],["Which of the following can only be used when training data are linearly separable?","Task Statement:\n\nIdentify the method that can only be used when training data are linearly separable.\nKey Details:\n\n- Training data must be linearly separable\n- Method that relies on linear separability\nRelevant Formulas:\n\nN\/A\nSteps to Solve:\n\n1. Understand the concept of linear separability in training data.\n2. Identify the method that specifically requires linear separability for successful training.\n3. Select the method that can only be used when training data are linearly separable.\nMissing Data:\n\nNone","1. Linear separability in training data means that the data points can be separated by a straight line.\n2. Linear hard-margin SVM requires the training data to be linearly separable in order to find the optimal hyperplane that maximizes the margin between classes.\n3. Linear Logistic Regression and Linear Soft margin SVM can handle non-linearly separable data by introducing regularization or soft margins.\n4. The centroid method is a simple classification technique that does not rely on linear separability.\n\n","A","A"],["Which of the following are the spatial clustering algorithms?","Key Details:\n\n- Spatial clustering algorithms\n- List of algorithms to determine which are spatial clustering algorithms\nRelevant Formulas:\n\nN\/A\nSteps to Solve:\n\n1. Identify the algorithms provided in the list.\n2. Determine which algorithms are spatial clustering algorithms based on their characteristics and definitions.\n3. List the spatial clustering algorithms from the given options.\nMissing Data:\n\nList of algorithms provided for identification.","1. Partitioning based clustering and K-means clustering are traditional clustering algorithms that do not specifically focus on spatial data.\n2. Grid based clustering, on the other hand, is a spatial clustering algorithm that divides the data space into a grid structure to perform clustering.\n3. Therefore, the correct answer is D. All of the above, as Grid based clustering is a spatial clustering algorithm.\n\n","D","D"],["Statement 1| The maximum margin decision boundaries that support vector machines construct have the lowest generalization error among all linear classifiers. Statement 2| Any decision boundary that we get from a generative model with classconditional Gaussian distributions could in principle be reproduced with an SVM and a polynomial kernel of degree less than or equal to three.","Task Statement:\n\nUnderstand the advantages of maximum margin decision boundaries in support vector machines compared to decision boundaries from generative models.\nKey Details:\n\n- Maximum margin decision boundaries in SVMs have the lowest generalization error among all linear classifiers.\n- Decision boundaries from generative models with class-conditional Gaussian distributions can be reproduced with an SVM using a polynomial kernel of degree less than or equal to three.\nRelevant Formulas:\n\nN\/A\nSteps to Solve:\n\n1. Compare the generalization error of maximum margin decision boundaries in SVMs with other linear classifiers.\n2. Understand the relationship between decision boundaries from generative models and SVMs with polynomial kernels.\nMissing Data:\n\nNone","1. The first statement is true as it highlights the advantage of maximum margin decision boundaries in SVMs having the lowest generalization error among all linear classifiers.\n2. The second statement is also true as it mentions that decision boundaries from generative models with class-conditional Gaussian distributions can be replicated using an SVM with a polynomial kernel of degree less than or equal to three.\n\nTherefore, both statements are true.\n\n","A","D"],["Statement 1| L2 regularization of linear models tends to make models more sparse than L1 regularization. Statement 2| Residual connections can be found in ResNets and Transformers.","Task Statement:\n\nUnderstand the characteristics of L2 and L1 regularization in linear models and the presence of residual connections in ResNets and Transformers.\nKey Details:\n\n- L2 regularization tends to make models more sparse than L1 regularization.\n- Residual connections are present in ResNets and Transformers.\nRelevant Formulas:\n\nN\/A\nSteps to Solve:\n\n1. Understand the impact of L2 and L1 regularization on model sparsity.\n2. Recognize the use of residual connections in ResNets and Transformers.\nMissing Data:\n\nNone","- Statement 1: L2 regularization tends to make models more sparse than L1 regularization. This statement is false because L1 regularization promotes sparsity by encouraging some of the coefficients to be exactly zero, while L2 regularization penalizes large coefficients but does not typically lead to sparsity.\n- Statement 2: Residual connections can be found in ResNets and Transformers. This statement is true as residual connections are a key component in ResNets and Transformers architectures.\n\n","A","D"],["Suppose we like to calculate P(H|E, F) and we have no conditional independence information. Which of the following sets of numbers are sufficient for the calculation?","Task Statement:\n\nIdentify the necessary information to calculate P(H|E, F) without conditional independence information.\nKey Details:\n\n- P(H)\n- P(E)\n- P(F)\n- P(H, E)\n- P(H, F)\n- P(E, F)\n- P(H, E, F)\nRelevant Formulas:\n\nP(H|E, F) = P(H, E, F) \/ P(E, F)\nSteps to Solve:\n\n1. Calculate P(H, E, F) using the provided values.\n2. Calculate P(E, F) using the provided values.\n3. Substitute the calculated values into the formula: P(H|E, F) = P(H, E, F) \/ P(E, F)\n4. Solve for P(H|E, F).\nMissing Data:\n\nNone","To calculate P(H|E, F) without conditional independence information, we need the joint probabilities P(H, E, F) and P(E, F). From these values, we can use the formula P(H|E, F) = P(H, E, F) \/ P(E, F) to find the conditional probability.\n\n","A","B"],["Which among the following prevents overfitting when we perform bagging?","Task Statement:\n\nIdentify the method that prevents overfitting when performing bagging.\nKey Details:\n\nBagging (Bootstrap Aggregating)\nOverfitting prevention method\nRelevant Formulas:\n\nN\/A\nSteps to Solve:\n\nUnderstand the concept of bagging and overfitting\nIdentify the method that specifically prevents overfitting in the context of bagging\nMissing Data:\n\nNone","Bagging involves creating multiple subsets of the training data through sampling with replacement and training multiple classifiers. Overfitting can occur when these classifiers are too complex and memorize the noise in the training data. To prevent overfitting in bagging, it is important to use weak classifiers that are not too complex and prone to overfitting.\n\n","A","B"],["Statement 1| PCA and Spectral Clustering (such as Andrew Ng\u2019s) perform eigendecomposition on two different matrices. However, the size of these two matrices are the same. Statement 2| Since classification is a special case of regression, logistic regression is a special case of linear regression.","Task Statement:\n\nUnderstand the relationship between PCA, Spectral Clustering, eigendecomposition, classification, regression, logistic regression, and linear regression.\nKey Details:\n\n- PCA and Spectral Clustering perform eigendecomposition on different matrices with the same size.\n- Classification is a special case of regression.\n- Logistic regression is a special case of linear regression.\nRelevant Formulas:\n\nN\/A\nSteps to Solve:\n\n1. Understand that PCA and Spectral Clustering use eigendecomposition on different matrices of the same size.\n2. Recognize that classification is a subset of regression.\n3. Identify logistic regression as a specific form of linear regression.\nMissing Data:\n\nNone","1. PCA and Spectral Clustering perform eigendecomposition on different matrices but of the same size, as stated.\n2. Classification is indeed a special case of regression, as mentioned.\n3. Logistic regression is a specific form of linear regression, as indicated.\n\nTherefore, Statement 1 is True, True, and Statement 2 is True, True.\n\n","A","B"],["Statement 1| The Stanford Sentiment Treebank contained movie reviews, not book reviews. Statement 2| The Penn Treebank has been used for language modeling.","Task Statement:\n\nIdentify the datasets associated with specific types of reviews and language modeling.\nKey Details:\n\n- Stanford Sentiment Treebank: movie reviews\n- Penn Treebank: used for language modeling\nRelevant Formulas:\n\nN\/A\nSteps to Solve:\n\n1. Associate Stanford Sentiment Treebank with movie reviews.\n2. Associate Penn Treebank with language modeling.\nMissing Data:\n\nNone","- Statement 1 states that the Stanford Sentiment Treebank contained movie reviews, which is true based on the key details provided.\n- Statement 2 states that the Penn Treebank has been used for language modeling, which is also true based on the key details provided.\n\nTherefore, both statements are true.\n\n","A","A"],["What is the dimensionality of the null space of the following matrix? A = [[3, 2, \u22129], [\u22126, \u22124, 18], [12, 8, \u221236]]","Task Statement:\n\nDetermine the dimensionality of the null space of a given matrix.\nKey Details:\n\nMatrix A: [[3, 2, \u22129], [\u22126, \u22124, 18], [12, 8, \u221236]]\nRelevant Formulas:\n\nNullity = n - rank(A)\nSteps to Solve:\n\nFind the rank of matrix A using row reduction or other methods.\nCalculate the nullity by subtracting the rank from the number of columns (n) of matrix A.\nMissing Data:\n\nNone","To find the dimensionality of the null space of the matrix A, we need to calculate the rank of the matrix first. Then, we can use the formula Nullity = n - rank(A), where n is the number of columns in matrix A.\n\nBy performing row operations or other methods, we can reduce matrix A to row-echelon form or reduced row-echelon form to determine its rank.\n\nAfter calculating the rank of matrix A, we can subtract it from the number of columns (which is 3 in this case) to find the nullity, which represents the dimensionality of the null space.\n\n","C","C"],["What are support vectors?","Task Statement:\n\nDefine support vectors in the context of machine learning.\nKey Details:\n\nSupport vectors are data points that define the decision boundary in a machine learning model.\nThey are the closest points to the hyperplane that separates classes in a support vector machine (SVM).\nRelevant Formulas:\n\nN\/A\nSteps to Solve:\n\nUnderstand that support vectors are crucial in SVM as they determine the optimal hyperplane.\nIdentify the data points that are support vectors by their proximity to the decision boundary.\nRecognize that support vectors play a key role in the classification of new data points.\nMissing Data:\n\nNone","Support vectors are the data points that are closest to the decision boundary in a support vector machine (SVM). They are crucial in defining the optimal hyperplane that separates classes. Therefore, the correct answer should be the option that best describes this characteristic.\n\n","A","B"],["Statement 1| Word2Vec parameters were not initialized using a Restricted Boltzman Machine. Statement 2| The tanh function is a nonlinear activation function.","Task Statement:\n\nIdentify key information related to Word2Vec and the tanh function.\nKey Details:\n\n- Word2Vec parameters were not initialized using a Restricted Boltzman Machine\n- The tanh function is a nonlinear activation function\nRelevant Formulas:\n\nN\/A\nSteps to Solve:\n\n1. Understand the implications of not initializing Word2Vec parameters with RBM\n2. Recognize the characteristics and role of the tanh function as a nonlinear activation function\nMissing Data:\n\nNone","1. Word2Vec parameters were not initialized using a Restricted Boltzman Machine, which is true. Word2Vec typically uses techniques like Skip-gram or Continuous Bag of Words (CBOW) for initialization.\n2. The tanh function is indeed a nonlinear activation function, as it squashes the input values between -1 and 1, allowing for non-linear transformations.\n\nTherefore, Statement 1 is True and Statement 2 is True.\n","A","A"],["If your training loss increases with number of epochs, which of the following could be a possible issue with the learning process?","Task Statement:\n\nIdentify a possible issue with the learning process if the training loss increases with the number of epochs.\nKey Details:\n\n- Training loss increases with the number of epochs\nRelevant Formulas:\n\nNone\nSteps to Solve:\n\n1. Check for overfitting: If the training loss increases while the validation loss decreases, it could indicate overfitting.\n2. Evaluate learning rate: A high learning rate may cause the loss to increase instead of converging.\n3. Consider model complexity: A complex model may struggle to generalize, leading to an increase in training loss.\nMissing Data:\n\nNone","If the training loss is increasing with the number of epochs, it indicates that the model is not learning effectively. This could be due to various reasons such as overfitting, underfitting, or inappropriate hyperparameters like learning rate.\n\nA. Regularization is too low and model is overfitting: If the model is overfitting, it means it is learning the training data too well and not generalizing to new data. This can lead to an increase in training loss as the model memorizes noise in the data.\n\nB. Regularization is too high and model is underfitting: If the model is underfitting, it means it is too simple to capture the underlying patterns in the data. This can also lead to an increase in training loss as the model fails to learn the data effectively.\n\nC. Step size is too large: A large step size (learning rate) can cause the model to overshoot the optimal parameters, leading to instability and an increase in training loss.\n\nD. Step size is too small: A small step size can slow down the learning process, but it is less likely to cause a consistent increase in training loss.\n\nConsidering the options, the most likely issue causing the training loss to increase with the number of epochs is a high learning rate (step size).\n","C","C"],["Say the incidence of a disease D is about 5 cases per 100 people (i.e., P(D) = 0.05). Let Boolean random variable D mean a patient \u201chas disease D\u201d and let Boolean random variable TP stand for \"tests positive.\" Tests for disease D are known to be very accurate in the sense that the probability of testing positive when you have the disease is 0.99, and the probability of testing negative when you do not have the disease is 0.97. What is P(D | TP), the posterior probability that you have disease D when the test is positive?","Task Statement:\n\nCalculate the posterior probability of having disease D when the test is positive.\nKey Details:\n\nP(D) = 0.05\nP(TP | D) = 0.99\nP(TP | \u00acD) = 0.03\nRelevant Formulas:\n\nBayes' Theorem: P(D | TP) = (P(TP | D) * P(D)) \/ [P(TP | D) * P(D) + P(TP | \u00acD) * P(\u00acD)]\nSteps to Solve:\n\nSubstitute the given probabilities into Bayes' Theorem formula\nCalculate the posterior probability P(D | TP)\nMissing Data:\n\nNone","Given:\nP(D) = 0.05\nP(TP | D) = 0.99\nP(TP | \u00acD) = 0.03\n\nUsing Bayes' Theorem:\nP(D | TP) = (P(TP | D) * P(D)) \/ [P(TP | D) * P(D) + P(TP | \u00acD) * P(\u00acD)]\n\nSubstitute the values:\nP(D | TP) = (0.99 * 0.05) \/ [0.99 * 0.05 + 0.03 * 0.95]\nP(D | TP) = 0.0495 \/ (0.0495 + 0.0285)\nP(D | TP) = 0.0495 \/ 0.078\nP(D | TP) = 0.635\n\n","C","C"],["Statement 1| Traditional machine learning results assume that the train and test sets are independent and identically distributed. Statement 2| In 2017, COCO models were usually pretrained on ImageNet.","Task Statement:\n\nIdentify key statements related to traditional machine learning and COCO models.\nKey Details:\n\nStatement 1: Traditional machine learning assumes independent and identically distributed train and test sets.\nStatement 2: In 2017, COCO models were typically pretrained on ImageNet.\nRelevant Formulas:\n\nN\/A\nSteps to Solve:\n\n1. Understand the implications of traditional machine learning assumptions.\n2. Recognize the common practice of pretraining COCO models on ImageNet in 2017.\nMissing Data:\n\nNone","1. Statement 1 is true because traditional machine learning indeed assumes that the train and test sets are independent and identically distributed.\n2. Statement 2 is also true as in 2017, it was common practice to pretrained COCO models on ImageNet.\n\n","A","A"],["Statement 1| The values of the margins obtained by two different kernels K1(x, x0) and K2(x, x0) on the same training set do not tell us which classifier will perform better on the test set. Statement 2| The activation function of BERT is the GELU.","Task Statement:\n\nUnderstand the implications of the given statements regarding kernel margins and BERT activation function.\nKey Details:\n\n- Statement 1: Margins of K1(x, x0) and K2(x, x0) on the same training set do not predict test set performance.\n- Statement 2: BERT uses the GELU activation function.\nRelevant Formulas:\n\nN\/A\nSteps to Solve:\n\n1. Acknowledge that kernel margins alone may not indicate test set performance accurately.\n2. Note that BERT utilizes the GELU activation function.\nMissing Data:\n\nNone","1. Statement 1 is true because the margins obtained by different kernels on the same training set do not necessarily correlate with test set performance.\n2. Statement 2 is true as BERT indeed uses the GELU activation function.\n\n","A","A"],["Which of the following is a clustering algorithm in machine learning?","Task Statement:\n\nIdentify a clustering algorithm in machine learning.\nKey Details:\n\n- Clustering algorithms group similar data points together based on certain criteria.\n- Common clustering algorithms include K-means, DBSCAN, and Hierarchical clustering.\nRelevant Formulas:\n\nN\/A\nSteps to Solve:\n\nReview the options provided and identify the clustering algorithm among them.\nChoose the algorithm that groups data points based on similarity.\nMissing Data:\n\nNone","- Expectation Maximization is an algorithm used for clustering in machine learning, specifically for Gaussian Mixture Models.\n- CART (Classification and Regression Trees) is a decision tree algorithm used for classification and regression tasks, not clustering.\n- Gaussian Na\u00efve Bayes is a probabilistic classification algorithm, not a clustering algorithm.\n- Apriori is an algorithm used for association rule mining, not clustering.\n\n","A","A"],["You've just finished training a decision tree for spam classification, and it is getting abnormally bad performance on both your training and test sets. You know that your implementation has no bugs, so what could be causing the problem?","Task Statement:\n\nIdentify potential reasons for abnormally bad performance of a decision tree for spam classification.\nKey Details:\n\n- Decision tree model\n- Abnormally bad performance on both training and test sets\n- Implementation has no bugs\nRelevant Formulas:\n\nN\/A\nSteps to Solve:\n\n1. Check for overfitting: Decision tree may be too complex and fitting noise in the data.\n2. Inspect data quality: Ensure data is clean, relevant, and representative.\n3. Evaluate feature selection: Verify if the right features are being used for classification.\n4. Consider hyperparameters: Adjust parameters like tree depth, minimum samples per leaf, etc.\n5. Explore ensemble methods: Try ensemble techniques like Random Forest to improve performance.\nMissing Data:\n\nNone","Given that the implementation has no bugs, the abnormally bad performance on both the training and test sets could be due to overfitting. Overfitting occurs when the decision tree is too complex and captures noise in the data, leading to poor generalization.\n\n","C","A"],["K-fold cross-validation is","Task Statement:\n\nExplain K-fold cross-validation.\nKey Details:\n\nK-fold cross-validation is a technique used in machine learning to assess the performance of a model.\nIt involves dividing the dataset into K subsets, using K-1 subsets for training and the remaining subset for testing.\nThis process is repeated K times, with each subset used as the test set exactly once.\nThe final performance metric is usually the average of the performance obtained in each iteration.\nRelevant Formulas:\n\nN\/A\nSteps to Solve:\n\nDefine K-fold cross-validation as a technique for evaluating the performance of a machine learning model.\nExplain the process of dividing the dataset into K subsets and iteratively training and testing the model.\nHighlight that the final performance metric is typically the average of the results obtained in each iteration.\nMissing Data:\n\nNone","K-fold cross-validation involves dividing the dataset into K subsets and using K-1 subsets for training and the remaining subset for testing. This process is repeated K times, with each subset used as the test set exactly once. Since the process is repeated K times, the complexity of K-fold cross-validation is linear in K.\n\n","A","A"],["Statement 1| Industrial-scale neural networks are normally trained on CPUs, not GPUs. Statement 2| The ResNet-50 model has over 1 billion parameters.","Task Statement:\n\nIdentify key information about training neural networks on CPUs and the number of parameters in the ResNet-50 model.\nKey Details:\n\n- Industrial-scale neural networks are typically trained on CPUs, not GPUs.\n- The ResNet-50 model has over 1 billion parameters.\nRelevant Formulas:\n\nN\/A\nSteps to Solve:\n\n1. Note that industrial-scale neural networks are trained on CPUs.\n2. Recognize that the ResNet-50 model has over 1 billion parameters.\nMissing Data:\n\nNone","1. The statement \"Industrial-scale neural networks are normally trained on CPUs, not GPUs\" is true.\n2. The statement \"The ResNet-50 model has over 1 billion parameters\" is true.\n\nTherefore, the correct answer is A. True, True.\n\n","A","B"],["Given two Boolean random variables, A and B, where P(A) = 1\/2, P(B) = 1\/3, and P(A | \u00acB) = 1\/4, what is P(A | B)?","Task Statement:\n\nCalculate the conditional probability of A given B.\nKey Details:\n\nP(A) = 1\/2\nP(B) = 1\/3\nP(A | \u00acB) = 1\/4\nRelevant Formulas:\n\nConditional Probability: P(A | B) = P(A \u2229 B) \/ P(B)\nSteps to Solve:\n\nCalculate P(A \u2229 \u00acB) using P(A | \u00acB) = P(A \u2229 \u00acB) \/ P(\u00acB)\nCalculate P(\u00acB) = 1 - P(B)\nCalculate P(A \u2229 B) using P(A \u2229 B) = P(A) - P(A \u2229 \u00acB)\nCalculate P(A | B) using the formula\nMissing Data:\n\nNone","1. Calculate P(\u00acB) = 1 - P(B) = 1 - 1\/3 = 2\/3\n2. Calculate P(A \u2229 \u00acB) using P(A | \u00acB) = P(A \u2229 \u00acB) \/ P(\u00acB) => 1\/4 = P(A \u2229 \u00acB) \/ 2\/3 => P(A \u2229 \u00acB) = 2\/12 = 1\/6\n3. Calculate P(A \u2229 B) using P(A \u2229 B) = P(A) - P(A \u2229 \u00acB) = 1\/2 - 1\/6 = 3\/6 - 1\/6 = 2\/6 = 1\/3\n4. Calculate P(A | B) using the formula P(A | B) = P(A \u2229 B) \/ P(B) = (1\/3) \/ (1\/3) = 1\n\n","D","D"],["Existential risks posed by AI are most commonly associated with which of the following professors?","Task Statement:\n\nIdentify the professor most commonly associated with existential risks posed by AI.\nKey Details:\n\n- Existential risks posed by AI\n- Association with a specific professor\nRelevant Formulas:\n\nN\/A\nSteps to Solve:\n\nResearch and identify professors commonly associated with existential risks posed by AI.\nDetermine which professor is most commonly linked to this topic.\nMissing Data:\n\nSpecific names of professors commonly associated with existential risks posed by AI.","Existential risks posed by AI are often associated with Stuart Russell, who is a prominent AI researcher and co-author of the book \"Artificial Intelligence: A Modern Approach,\" which discusses the potential risks and ethical considerations of AI.\n\n","C","C"],["Statement 1| Maximizing the likelihood of logistic regression model yields multiple local optimums. Statement 2| No classifier can do better than a naive Bayes classifier if the distribution of the data is known.","Task Statement:\n\nUnderstand the characteristics of logistic regression and naive Bayes classifiers.\nKey Details:\n\n- Logistic regression model can have multiple local optimums when maximizing likelihood.\n- Naive Bayes classifier performs optimally when the distribution of the data is known.\nRelevant Formulas:\n\nN\/A\nSteps to Solve:\n\n1. Understand the concept of local optimums in logistic regression.\n2. Recognize the importance of knowing the data distribution for naive Bayes classifier.\nMissing Data:\n\nNone","- Statement 1 is True because logistic regression models can have multiple local optimums due to the nature of the optimization process.\n- Statement 2 is False because while naive Bayes classifier assumes independence between features, it can still perform well even if the distribution of the data is not known.\n\n","C","B"],["For Kernel Regression, which one of these structural assumptions is the one that most affects the trade-off between underfitting and overfitting:","Task Statement:\n\nIdentify the structural assumption in Kernel Regression that most affects the trade-off between underfitting and overfitting.\nKey Details:\n\n- Structural assumptions in Kernel Regression\n- Impact on the trade-off between underfitting and overfitting\nRelevant Formulas:\n\nN\/A\nSteps to Solve:\n\n1. Understand the structural assumptions in Kernel Regression.\n2. Determine which assumption has the most significant impact on the trade-off between underfitting and overfitting.\n3. Analyze how this assumption affects the model's performance.\nMissing Data:\n\nNone","The structural assumption in Kernel Regression that most affects the trade-off between underfitting and overfitting is the kernel width. The kernel width determines the smoothness of the regression function and can impact the model's ability to capture the underlying patterns in the data. A narrow kernel width may lead to overfitting, while a wide kernel width may result in underfitting.\n\n","C","C"],["Statement 1| The SVM learning algorithm is guaranteed to find the globally optimal hypothesis with respect to its object function. Statement 2| After being mapped into feature space Q through a radial basis kernel function, a Perceptron may be able to achieve better classification performance than in its original space (though we can\u2019t guarantee this).","Task Statement:\n\nUnderstand the characteristics of the SVM learning algorithm and the impact of feature space mapping on Perceptron performance.\nKey Details:\n\n- SVM learning algorithm finds the globally optimal hypothesis\n- Perceptron may achieve better classification performance in feature space Q with radial basis kernel function\nRelevant Formulas:\n\nN\/A\nSteps to Solve:\n\n1. Understand the guarantee of finding the globally optimal hypothesis by SVM\n2. Consider the potential improvement in classification performance of Perceptron in feature space Q\nMissing Data:\n\nNone","1. Statement 1 is true because the SVM learning algorithm is designed to find the globally optimal hypothesis with respect to its objective function.\n2. Statement 2 is also true because when a Perceptron is mapped into a feature space Q through a radial basis kernel function, it may achieve better classification performance due to the non-linear separation capabilities of the kernel function.\n\n","A","A"],["For a Gaussian Bayes classifier, which one of these structural assumptions is the one that most affects the trade-off between underfitting and overfitting:","Task Statement:\n\nIdentify the structural assumption in a Gaussian Bayes classifier that most affects the trade-off between underfitting and overfitting.\nKey Details:\n\n- Gaussian Bayes classifier\n- Structural assumption affecting trade-off between underfitting and overfitting\nRelevant Formulas:\n\nN\/A\nSteps to Solve:\n\n1. Understand the structural assumptions in a Gaussian Bayes classifier.\n2. Identify the assumption that impacts the trade-off between underfitting and overfitting the most.\nMissing Data:\n\nNone","In a Gaussian Bayes classifier, the assumption that most affects the trade-off between underfitting and overfitting is the assumption about the covariance matrices. Assuming full class covariance matrices can lead to overfitting, while assuming diagonal class covariance matrices can lead to underfitting.\n\n","B","B"],["Statement 1| Overfitting is more likely when the set of training data is small. Statement 2| Overfitting is more likely when the hypothesis space is small.","Task Statement:\n\nIdentify factors that contribute to overfitting in machine learning models.\nKey Details:\n\n- Statement 1: Overfitting is more likely when the set of training data is small.\n- Statement 2: Overfitting is more likely when the hypothesis space is small.\nRelevant Formulas:\n\nN\/A\nSteps to Solve:\n\n1. Understand the impact of small training data on overfitting.\n2. Understand the impact of a small hypothesis space on overfitting.\n3. Compare and analyze the factors contributing to overfitting.\nMissing Data:\n\nNone","1. Statement 1 is true because when the training data is small, the model may memorize the noise in the data rather than capturing the underlying patterns, leading to overfitting.\n2. Statement 2 is false because overfitting is more likely when the hypothesis space is large, allowing the model to capture complex patterns that may not generalize well to unseen data.\n\n","C","D"],["Statement 1| Besides EM, gradient descent can be used to perform inference or learning on Gaussian mixture model. Statement 2 | Assuming a fixed number of attributes, a Gaussian-based Bayes optimal classifier can be learned in time linear in the number of records in the dataset.","Task Statement:\n\nUnderstand the use of gradient descent in Gaussian mixture models and the time complexity of learning a Gaussian-based Bayes optimal classifier.\nKey Details:\n\n- Gradient descent can be used for inference or learning in Gaussian mixture models.\n- Gaussian-based Bayes optimal classifier can be learned in time linear to the number of records in the dataset.\nRelevant Formulas:\n\nNot applicable\nSteps to Solve:\n\n1. Understand the application of gradient descent in Gaussian mixture models.\n2. Recognize the linear time complexity of learning a Gaussian-based Bayes optimal classifier.\nMissing Data:\n\nNone","1. Gradient descent can indeed be used for inference or learning in Gaussian mixture models, so Statement 1 is True.\n2. A Gaussian-based Bayes optimal classifier can be learned in time linear to the number of records in the dataset, which means Statement 2 is also True.\n\n","A","A"],["Statement 1| In a Bayesian network, the inference results of the junction tree algorithm are the same as the inference results of variable elimination. Statement 2| If two random variable X and Y are conditionally independent given another random variable Z, then in the corresponding Bayesian network, the nodes for X and Y are d-separated given Z.","Task Statement:\n\nUnderstand the relationship between the junction tree algorithm and variable elimination in Bayesian networks, as well as the concept of d-separation in Bayesian networks.\nKey Details:\n\n- Statement 1: In a Bayesian network, the inference results of the junction tree algorithm are the same as the inference results of variable elimination.\n- Statement 2: If two random variables X and Y are conditionally independent given another random variable Z, then in the corresponding Bayesian network, the nodes for X and Y are d-separated given Z.\nRelevant Formulas:\n\nNot applicable\nSteps to Solve:\n\n1. Understand the junction tree algorithm and variable elimination in Bayesian networks.\n2. Recognize the equivalence of inference results between the junction tree algorithm and variable elimination.\n3. Learn about d-separation in Bayesian networks and its relationship to conditional independence.\nMissing Data:\n\nNone","1. The statement 1 is true because in Bayesian networks, both the junction tree algorithm and variable elimination are methods used for inference, and they should yield the same results.\n2. The statement 2 is also true based on the concept of d-separation in Bayesian networks, where if X and Y are conditionally independent given Z, then the nodes for X and Y are d-separated given Z.\n\n","A","C"],["Given a large dataset of medical records from patients suffering from heart disease, try to learn whether there might be different clusters of such patients for which we might tailor separate treatments. What kind of learning problem is this?","Task Statement:\n\nIdentify the type of learning problem presented in analyzing a dataset of medical records from patients with heart disease.\nKey Details:\n\n- Large dataset of medical records\n- Patients suffering from heart disease\n- Goal is to determine if there are different clusters of patients for tailored treatments\nRelevant Formulas:\n\nN\/A\nSteps to Solve:\n\n1. Analyze the dataset using clustering algorithms to identify distinct groups of patients.\n2. Evaluate the results to determine if there are separate clusters that suggest tailored treatments.\nMissing Data:\n\nNone","The task involves analyzing a dataset of medical records from patients with heart disease to identify different clusters of patients for tailored treatments. This type of problem falls under unsupervised learning, where the goal is to discover patterns or structures in the data without explicit labels or guidance.\n","B","B"],["What would you do in PCA to get the same projection as SVD?","Task Statement:\n\nIdentify the steps needed in PCA to achieve the same projection as SVD.\nKey Details:\n\nPrincipal Component Analysis (PCA)\nSingular Value Decomposition (SVD)\nProjection in PCA\nProjection in SVD\nRelevant Formulas:\n\nNone\nSteps to Solve:\n\nPerform PCA on the data to obtain the principal components.\nUse the principal components to project the data onto a lower-dimensional space.\nEnsure that the projection obtained in PCA matches the projection achieved in SVD.\nMissing Data:\n\nNone","In PCA, the first step is to transform the data to zero mean by subtracting the mean of each feature from the data. This step is essential to ensure that the data is centered around the origin. By doing this, PCA achieves the same projection as SVD, which also centers the data around the origin.\n\n","A","A"],["Statement 1| The training error of 1-nearest neighbor classifier is 0. Statement 2| As the number of data points grows to infinity, the MAP estimate approaches the MLE estimate for all possible priors. In other words, given enough data, the choice of prior is irrelevant.","Task Statement:\n\nUnderstand the relationship between the training error of a 1-nearest neighbor classifier and the MAP estimate compared to the MLE estimate as the number of data points approaches infinity.\nKey Details:\n\n- Training error of 1-nearest neighbor classifier: 0\n- Relationship between MAP estimate and MLE estimate as data points approach infinity\nRelevant Formulas:\n\nNone\nSteps to Solve:\n\n1. Consider the training error of 1-nearest neighbor classifier being 0.\n2. Analyze the relationship between the MAP estimate and MLE estimate as the number of data points approaches infinity.\n3. Understand that with enough data points, the choice of prior becomes irrelevant.\nMissing Data:\n\nNone","1. The statement that the training error of 1-nearest neighbor classifier is 0 implies that the classifier perfectly fits the training data.\n2. The statement that as the number of data points grows to infinity, the MAP estimate approaches the MLE estimate for all possible priors indicates that with a large amount of data, the choice of prior becomes irrelevant as both estimates converge.\n\n","A","C"],["When doing least-squares regression with regularisation (assuming that the optimisation can be done exactly), increasing the value of the regularisation parameter \u03bb the testing error.","Task Statement:\n\nUnderstand the relationship between the regularisation parameter \u03bb and the testing error in least-squares regression with regularisation.\nKey Details:\n\n- Least-squares regression with regularisation\n- Regularisation parameter (\u03bb)\n- Testing error\nRelevant Formulas:\n\nNot applicable\nSteps to Solve:\n\n- Increase the value of the regularisation parameter \u03bb\n- Observe the impact on the testing error\nMissing Data:\n\nNone","When the regularisation parameter \u03bb is increased in least-squares regression with regularisation, it penalizes the model complexity more. This penalty can lead to a simpler model that may generalize better to unseen data, reducing the chance of overfitting. Therefore, increasing \u03bb can help prevent overfitting and potentially decrease the testing error.\n\n","C","A"],["Which of the following best describes what discriminative approaches try to model? (w are the parameters in the model)","Task Statement:\n\nIdentify the description of what discriminative approaches aim to model in relation to the parameters in the model.\nKey Details:\n\n- Discriminative approaches\n- Parameters (w) in the model\nRelevant Formulas:\n\nNot applicable\nSteps to Solve:\n\n1. Understand the concept of discriminative approaches in modeling.\n2. Determine the relationship between discriminative approaches and the parameters (w) in the model.\n3. Choose the description that best fits the modeling goal of discriminative approaches.\nMissing Data:\n\nNone","Discriminative approaches in modeling aim to directly model the conditional probability of the output variable (y) given the input variable (x) and the parameters (w) in the model. Therefore, the best description of what discriminative approaches try to model is p(y|x, w).\n\n","A","A"],["Statement 1| CIFAR-10 classification performance for convolution neural networks can exceed 95%. Statement 2| Ensembles of neural networks do not improve classification accuracy since the representations they learn are highly correlated.","Task Statement:\n\nEvaluate statements about CIFAR-10 classification performance and the impact of ensembles of neural networks on classification accuracy.\nKey Details:\n\n- Statement 1: CIFAR-10 classification performance can exceed 95% for convolutional neural networks.\n- Statement 2: Ensembles of neural networks may not improve classification accuracy due to highly correlated learned representations.\nRelevant Formulas:\n\nN\/A\nSteps to Solve:\n\n1. Verify the accuracy claim for CIFAR-10 classification performance.\n2. Assess the impact of ensembles of neural networks on classification accuracy.\nMissing Data:\n\nNone","1. Statement 1 claims that CIFAR-10 classification performance for convolutional neural networks can exceed 95%. This statement is true as advanced CNN models have achieved accuracy levels above 95% on the CIFAR-10 dataset.\n2. Statement 2 suggests that ensembles of neural networks do not improve classification accuracy due to highly correlated learned representations. This statement is false because ensembles of neural networks, by combining multiple models, can often improve classification accuracy by reducing overfitting and capturing diverse patterns in the data.\n\n","C","C"],["Which of the following points would Bayesians and frequentists disagree on?","Task Statement:\n\nIdentify points of disagreement between Bayesians and frequentists.\nKey Details:\n\n- Approach to probability\n- Treatment of prior beliefs\n- Interpretation of probability\n- Handling of uncertainty\nRelevant Formulas:\n\nNone\nSteps to Solve:\n\n1. Understand the fundamental differences between Bayesian and frequentist approaches to probability.\n2. Compare how each approach deals with prior beliefs, interpretation of probability, and uncertainty.\n3. Identify specific points of disagreement based on these differences.\nMissing Data:\n\nNone","Bayesians and frequentists fundamentally differ in their approach to probability. Bayesians incorporate prior beliefs into their analysis using prior distributions, while frequentists do not. Frequentists rely on the concept of long-run frequencies and do not assign probabilities to hypotheses or parameters. Therefore, the use of prior distributions on parameters in a probabilistic model (Option C) would be a point of disagreement between Bayesians and frequentists.\n\n","C","C"],["Statement 1| The BLEU metric uses precision, while the ROGUE metric uses recall. Statement 2| Hidden markov models were frequently used to model English sentences.","Task Statement:\n\nIdentify key information about the BLEU and ROGUE metrics and Hidden Markov Models.\nKey Details:\n\n- BLEU metric: Uses precision\n- ROGUE metric: Uses recall\n- Hidden Markov Models: Frequently used to model English sentences\nRelevant Formulas:\n\nN\/A\nSteps to Solve:\n\n1. Understand the difference between precision and recall in the context of BLEU and ROGUE metrics.\n2. Recognize the common usage of Hidden Markov Models in modeling English sentences.\nMissing Data:\n\nNone","1. The statement that the BLEU metric uses precision is correct. BLEU (Bilingual Evaluation Understudy) metric is a method for evaluating the quality of text which has been machine-translated from one natural language to another. It uses precision to measure how many of the generated words and phrases appear in the reference translation.\n2. The statement that the ROGUE metric uses recall is incorrect. ROGUE (Recall-Oriented Understudy for Gisting Evaluation) metric is also used for evaluating text generated by natural language processing tasks like machine translation, but it focuses on recall, measuring how many of the reference words and phrases appear in the generated text.\n3. Hidden Markov Models are indeed frequently used to model English sentences. Hidden Markov Models are statistical models that can be used to model sequences of observable events, making them suitable for tasks like speech recognition, part-of-speech tagging, and language modeling.\n\n","A","A"],["Statement 1| ImageNet has images of various resolutions. Statement 2| Caltech-101 has more images than ImageNet.","Task Statement:\n\nDetermine which dataset has a higher total resolution based on the given statements.\nKey Details:\n\n- ImageNet: images of various resolutions\n- Caltech-101: more images than ImageNet\nRelevant Formulas:\n\nTotal resolution = number of images * average resolution\nSteps to Solve:\n\nCompare the total resolution of ImageNet and Caltech-101 based on the number of images and their resolutions.\nCalculate the total resolution for each dataset using the formula.\nIdentify which dataset has a higher total resolution.\nMissing Data:\n\nAverage resolution of images in each dataset.","To determine which dataset has a higher total resolution, we need to consider the number of images and their resolutions in each dataset. \nGiven that ImageNet has images of various resolutions and Caltech-101 has more images than ImageNet, we can compare the total resolution of the two datasets.\n\nLet's assume:\n- Average resolution of images in ImageNet = R1\n- Average resolution of images in Caltech-101 = R2\n- Number of images in ImageNet = N1\n- Number of images in Caltech-101 = N2\n\nTotal resolution for ImageNet = N1 * R1\nTotal resolution for Caltech-101 = N2 * R2\n\nSince Caltech-101 has more images than ImageNet, N2 > N1. However, we do not have information about the average resolutions of the images in each dataset, so we cannot definitively determine which dataset has a higher total resolution.\n\n","C","C"],["Which of the following is more appropriate to do feature selection?","Task Statement:\n\nIdentify the more appropriate method for feature selection.\nKey Details:\n\n- Feature selection methods\n- Criteria for selecting appropriate method\nRelevant Formulas:\n\nNot applicable\nSteps to Solve:\n\n1. Evaluate different feature selection methods.\n2. Consider the criteria for selecting an appropriate method.\n3. Choose the method that best fits the criteria.\nMissing Data:\n\nNone","Feature selection is the process of selecting a subset of relevant features for use in model construction. Ridge and Lasso are both regularization techniques used in linear regression to prevent overfitting by adding a penalty term to the cost function. However, Lasso performs feature selection by shrinking the coefficients of less important features to zero, effectively removing them from the model. Ridge, on the other hand, only shrinks the coefficients towards zero but does not eliminate features entirely. Therefore, Lasso is more appropriate for feature selection.\n\n","B","B"],["Suppose you are given an EM algorithm that finds maximum likelihood estimates for a model with latent variables. You are asked to modify the algorithm so that it finds MAP estimates instead. Which step or steps do you need to modify?","Task Statement:\n\nIdentify the step or steps in the EM algorithm that need to be modified to find MAP estimates instead of maximum likelihood estimates.\nKey Details:\n\n- EM algorithm used for finding maximum likelihood estimates\n- Need to modify the algorithm to find MAP estimates\nRelevant Formulas:\n\nN\/A\nSteps to Solve:\n\nIdentify the step in the EM algorithm where the likelihood term is maximized\nModify this step to incorporate the prior distribution to find the MAP estimates\nMissing Data:\n\nNone","In the EM algorithm, the Maximization step is where the likelihood term is maximized to find maximum likelihood estimates. To modify the algorithm to find MAP estimates, we need to incorporate the prior distribution. Therefore, we need to modify the Maximization step to include the prior distribution in order to find MAP estimates.\n\n","B","B"],["For a Gaussian Bayes classifier, which one of these structural assumptions is the one that most affects the trade-off between underfitting and overfitting:","Task Statement:\n\nIdentify the structural assumption in a Gaussian Bayes classifier that most affects the trade-off between underfitting and overfitting.\nKey Details:\n\n- Gaussian Bayes classifier\n- Structural assumption affecting trade-off between underfitting and overfitting\nRelevant Formulas:\n\nN\/A\nSteps to Solve:\n\n1. Understand the structural assumptions in a Gaussian Bayes classifier.\n2. Identify the assumption that impacts the trade-off between underfitting and overfitting the most.\nMissing Data:\n\nNone","In a Gaussian Bayes classifier, the assumption that most affects the trade-off between underfitting and overfitting is the assumption about the covariance matrices. When we assume full class covariance matrices, we are allowing for more flexibility in the model, which can lead to overfitting. On the other hand, assuming diagonal class covariance matrices imposes more constraints on the model, potentially leading to underfitting.\n\n","B","B"],["Statement 1| For any two variables x and y having joint distribution p(x, y), we always have H[x, y] \u2265 H[x] + H[y] where H is entropy function. Statement 2| For some directed graphs, moralization decreases the number of edges present in the graph.","Task Statement:\n\nUnderstand the properties of joint distribution and entropy, as well as the impact of moralization on directed graphs.\nKey Details:\n\n- Statement 1: H[x, y] \u2265 H[x] + H[y] for joint distribution p(x, y)\n- Statement 2: Moralization reduces the number of edges in some directed graphs\nRelevant Formulas:\n\n- Entropy function: H[x] = -\u03a3 p(x) * log(p(x))\nSteps to Solve:\n\n1. Understand the concept of joint distribution and entropy to analyze Statement 1\n2. Apply the entropy function to calculate H[x], H[y], and H[x, y] to verify the inequality in Statement 1\n3. Explore the process of moralization in directed graphs to understand its impact on edge reduction\nMissing Data:\n\nNone","1. Statement 1 is related to the properties of joint distribution and entropy. The entropy function H[x] is a measure of uncertainty or randomness in a random variable x. The joint entropy H[x, y] represents the uncertainty in the joint distribution of variables x and y. The inequality H[x, y] \u2265 H[x] + H[y] indicates that the joint entropy is always greater than or equal to the sum of individual entropies.\n2. Statement 2 is about the impact of moralization on directed graphs. Moralization is a process in graphical models where directed edges are converted into undirected edges by adding edges between the parents of a node. This process can lead to a reduction in the number of edges in some cases.\n\n","C","B"],["Which of the following is NOT supervised learning?","Key Details:\n\n- Supervised learning involves training a model on labeled data where the input and output are known.\n- Unsupervised learning involves finding patterns in data without explicit labels.\n- Reinforcement learning involves learning through trial and error based on rewards or penalties.\n- Semi-supervised learning uses a combination of labeled and unlabeled data for training.\n- The task is to identify the type of learning that is NOT supervised learning.\n\nRelevant Formulas:\n\nN\/A\n\nSteps to Solve:\n\n1. Understand the definitions of supervised, unsupervised, reinforcement, and semi-supervised learning.\n2. Identify the learning type that does not fit the definition of supervised learning.\n3. Select the option that corresponds to the type of learning that is NOT supervised learning.\n\nMissing Data:\n\nNone","Supervised learning involves training a model on labeled data where the input and output are known. PCA (Principal Component Analysis), Decision Tree, Linear Regression, and Naive Bayesian are all examples of supervised learning algorithms. However, PCA is actually an unsupervised learning technique used for dimensionality reduction and finding patterns in data without explicit labels. Therefore, PCA is NOT supervised learning.\n\n","A","A"],["Statement 1| A neural network's convergence depends on the learning rate. Statement 2| Dropout multiplies randomly chosen activation values by zero.","Task Statement:\n\nUnderstand the impact of learning rate on neural network convergence and the function of dropout in a neural network.\nKey Details:\n\n- Learning rate affects the convergence of a neural network\n- Dropout randomly sets activation values to zero during training\nRelevant Formulas:\n\nN\/A\nSteps to Solve:\n\n1. Adjust the learning rate to observe its impact on the convergence of the neural network.\n2. Implement dropout in the neural network and observe how it affects the training process.\nMissing Data:\n\nNone","- Statement 1 is true because the learning rate plays a crucial role in determining how quickly or slowly a neural network converges during training.\n- Statement 2 is true because dropout is a regularization technique that randomly sets a fraction of activation values to zero, which helps prevent overfitting and improves the generalization of the model.\n\n","A","A"],["Which one of the following is equal to P(A, B, C) given Boolean random variables A, B and C, and no independence or conditional independence assumptions between any of them?","Task Statement:\n\nDetermine the value of P(A, B, C) for Boolean random variables A, B, and C without assuming independence or conditional independence.\nKey Details:\n\nBoolean random variables A, B, C\nNo independence or conditional independence assumptions\nRelevant Formulas:\n\nNone\nSteps to Solve:\n\nSince there are no assumptions of independence or conditional independence, P(A, B, C) is the joint probability of all three variables occurring together.\nCalculate the joint probability P(A, B, C) based on the given information.\nMissing Data:\n\nNone","Since there are no assumptions of independence or conditional independence between A, B, and C, the joint probability P(A, B, C) is the probability of all three variables occurring together. Therefore, the correct answer should involve the joint probability of A, B, and C without any conditional probabilities.\n\n","C","C"],["Which of the following tasks can be best solved using Clustering.","Key Details:\n\n- Clustering is a machine learning technique used for grouping similar data points together.\n- Tasks that involve identifying patterns or grouping similar data points are best solved using clustering.\n- Clustering is unsupervised learning, meaning it does not require labeled data for training.\n- Examples of tasks suitable for clustering include customer segmentation, anomaly detection, and image segmentation.\nRelevant Formulas:\n\nN\/A\nSteps to Solve:\n\n1. Identify tasks that involve grouping similar data points or identifying patterns.\n2. Consider whether the task requires unsupervised learning.\n3. Evaluate if the task can benefit from clustering techniques such as K-means, hierarchical clustering, or DBSCAN.\nMissing Data:\n\nNone","Clustering is best suited for tasks that involve grouping similar data points together without the need for labeled data. Among the given options, predicting the amount of rainfall based on various cues would require regression techniques, detecting fraudulent credit card transactions would involve classification methods, and training a robot to solve a maze would likely involve reinforcement learning. Therefore, the task that aligns with the capabilities of clustering is not explicitly mentioned in the options provided.\n\n","D","B"],["After applying a regularization penalty in linear regression, you find that some of the coefficients of w are zeroed out. Which of the following penalties might have been used?","Task Statement:\n\nIdentify the regularization penalty used in linear regression that results in some coefficients being zeroed out.\nKey Details:\n\n- Regularization penalty applied in linear regression\n- Some coefficients of w are zeroed out\nRelevant Formulas:\n\n- Lasso (L1) regularization: \u03bb * ||w||\u2081\n- Ridge (L2) regularization: \u03bb * ||w||\u2082\u00b2\nSteps to Solve:\n\n- Check if the regularization penalty used is Lasso (L1) or Ridge (L2)\n- If some coefficients are zeroed out, Lasso (L1) regularization is likely used\nMissing Data:\n\nNone","In linear regression, when some coefficients of w are zeroed out after applying a regularization penalty, it indicates that the penalty used encourages sparsity in the coefficients. The Lasso (L1) regularization penalty is known for promoting sparsity by shrinking some coefficients to exactly zero. On the other hand, Ridge (L2) regularization does not typically zero out coefficients. Therefore, the correct penalty that might have been used in this scenario is the L1 norm.\n\n","B","D"],["A and B are two events. If P(A, B) decreases while P(A) increases, which of the following is true?","Task Statement:\n\nDetermine the relationship between the probabilities of events A and B based on the given information.\nKey Details:\n\n- Probability of events A and B occurring together: P(A, B) decreases\n- Probability of event A occurring: P(A) increases\nRelevant Formulas:\n\nNone\nSteps to Solve:\n\n1. Understand that P(A, B) refers to the probability of both events A and B occurring together.\n2. Recognize that if P(A, B) decreases while P(A) increases, events A and B are likely dependent.\n3. Conclude that the events A and B are dependent based on the given information.\nMissing Data:\n\nNone","If P(A, B) decreases while P(A) increases, it indicates that events A and B are dependent. When the joint probability decreases while the probability of one event increases, it suggests that the events are not independent of each other.\n\nGiven that events A and B are dependent, we can determine the relationship between the conditional probabilities P(A|B) and P(B|A) as well as the probability of event B (P(B)).\n\nIf P(A, B) decreases, it implies that the probability of both events occurring together is decreasing. This decrease in the joint probability can affect the conditional probabilities and the individual probabilities of events A and B.\n\n","B","B"],["Statement 1| When learning an HMM for a fixed set of observations, assume we do not know the true number of hidden states (which is often the case), we can always increase the training data likelihood by permitting more hidden states. Statement 2| Collaborative filtering is often a useful model for modeling users' movie preference.","Task Statement:\n\nIdentify key concepts related to Hidden Markov Models (HMM) and Collaborative Filtering.\nKey Details:\n\n- Hidden Markov Models (HMM)\n- True number of hidden states\n- Training data likelihood\n- Collaborative Filtering\n- Users' movie preference\nRelevant Formulas:\n\nN\/A\nSteps to Solve:\n\n1. Understand the concept of Hidden Markov Models (HMM) and the impact of the number of hidden states on training data likelihood.\n2. Explore how Collaborative Filtering is used to model users' movie preferences.\nMissing Data:\n\nNone","- Statement 1 is discussing Hidden Markov Models (HMM) and mentions that increasing the number of hidden states can improve training data likelihood, which is true.\n- Statement 2 is about Collaborative Filtering being useful for modeling users' movie preferences, which is also true.\n\n","A","A"],["You are training a linear regression model for a simple estimation task, and notice that the model is overfitting to the data. You decide to add in $\\ell_2$ regularization to penalize the weights. As you increase the $\\ell_2$ regularization coefficient, what will happen to the bias and variance of the model?","Task Statement:\n\nDetermine the effect of increasing $\\ell_2$ regularization coefficient on the bias and variance of a linear regression model.\nKey Details:\n\n- Linear regression model\n- Overfitting to the data\n- Adding $\\ell_2$ regularization\n- Increasing $\\ell_2$ regularization coefficient\nRelevant Formulas:\n\nNone\nSteps to Solve:\n\n1. Initially, the model is overfitting, leading to low bias and high variance.\n2. By increasing the $\\ell_2$ regularization coefficient, the model will penalize the weights more.\n3. This penalty will reduce the complexity of the model, leading to an increase in bias and a decrease in variance.\n4. Overall, increasing the $\\ell_2$ regularization coefficient will help in reducing overfitting by balancing bias and variance.\nMissing Data:\n\nNone","1. Initially, the model is overfitting, which means it has low bias and high variance.\n2. By adding $\\ell_2$ regularization and increasing the regularization coefficient, the model will penalize the weights more.\n3. This penalty will reduce the complexity of the model, leading to an increase in bias and a decrease in variance.\n4. Therefore, as the $\\ell_2$ regularization coefficient increases, bias will increase and variance will decrease.\n\n","B","B"],["Which PyTorch 1.8 command(s) produce $10\\times 5$ Gaussian matrix with each entry i.i.d. sampled from $\\mathcal{N}(\\mu=5,\\sigma^2=16)$ and a $10\\times 10$ uniform matrix with each entry i.i.d. sampled from $U[-1,1)$?","Task Statement:\n\nGenerate a $10\\times 5$ Gaussian matrix and a $10\\times 10$ uniform matrix using PyTorch 1.8 commands.\nKey Details:\n\nMatrix dimensions:\n- Gaussian matrix: $10\\times 5$\n- Uniform matrix: $10\\times 10$\nDistribution parameters:\n- Gaussian: $\\mu=5$, $\\sigma^2=16$\n- Uniform: $U[-1,1)$\nRelevant Formulas:\n\nPyTorch commands for generating random matrices\nSteps to Solve:\n\nUse the PyTorch `torch.randn` command to generate the $10\\times 5$ Gaussian matrix with mean $\\mu=5$ and standard deviation $\\sigma=4$.\nUse the PyTorch `torch.rand` command to generate the $10\\times 10$ uniform matrix with values sampled from $U[-1,1)$.\nMissing Data:\n\nNone","To generate a $10\\times 5$ Gaussian matrix with mean $\\mu=5$ and standard deviation $\\sigma=4$, we use the formula `5 + torch.randn(10,5) * 4`.\nTo generate a $10\\times 10$ uniform matrix with values sampled from $U[-1,1)$, we use the formula `2 * torch.rand(10,10) - 1`.\n\n","B","C"],["Statement 1| The ReLU's gradient is zero for $x<0$, and the sigmoid gradient $\\sigma(x)(1-\\sigma(x))\\le \\frac{1}{4}$ for all $x$. Statement 2| The sigmoid has a continuous gradient and the ReLU has a discontinuous gradient.","Task Statement:\n\nCompare the gradients of ReLU and sigmoid activation functions based on the given statements.\nKey Details:\n\n- ReLU gradient is zero for $x<0$\n- Sigmoid gradient $\\sigma(x)(1-\\sigma(x))\\le \\frac{1}{4}$ for all $x$\n- Sigmoid has a continuous gradient\n- ReLU has a discontinuous gradient\nRelevant Formulas:\n\nNone\nSteps to Solve:\n\n1. For ReLU:\n   - Gradient is zero for $x<0$\n   - Discontinuous at $x=0$\n\n2. For Sigmoid:\n   - Gradient satisfies $\\sigma(x)(1-\\sigma(x))\\le \\frac{1}{4}$ for all $x$\n   - Continuous gradient\nMissing Data:\n\nNone","1. For ReLU:\n   - The statement mentions that the ReLU's gradient is zero for $x<0$, which is true.\n   - The ReLU function is discontinuous at $x=0$.\n\n2. For Sigmoid:\n   - The statement mentions that the sigmoid gradient $\\sigma(x)(1-\\sigma(x))\\le \\frac{1}{4}$ for all $x$, which is true.\n   - The sigmoid function has a continuous gradient.\n\nBased on the given statements and the characteristics of ReLU and sigmoid functions, we can conclude that:\n- ReLU has a gradient of zero for $x<0$ and is discontinuous.\n- Sigmoid has a gradient satisfying $\\sigma(x)(1-\\sigma(x))\\le \\frac{1}{4}$ for all $x$ and has a continuous gradient.\n\nTherefore, the correct answer is:\n","A","A"],["Which is true about Batch Normalization?","Key Details:\n\n- Batch Normalization is a technique used in neural networks to improve training speed and stability.\n- It normalizes the input of each layer by adjusting and scaling the activations.\n- It helps in reducing internal covariate shift and allows for higher learning rates.\n- Batch Normalization is typically applied before the activation function in a neural network.\n- It involves normalizing the activations of each mini-batch during training.\n- It introduces additional parameters (gamma and beta) to scale and shift the normalized values.\n- Batch Normalization can act as a regularizer in neural networks.\n- It is commonly used in deep learning models to improve performance and convergence.\n- Batch Normalization can be applied to convolutional neural networks as well as fully connected networks.\n\nRelevant Formulas:\n\nN\/A\n\nSteps to Solve:\n\nN\/A\n\nMissing Data:\n\nN\/A","A. After applying batch normalization, the layer\u2019s activations will follow a standard Gaussian distribution - This statement is not true. Batch normalization normalizes the activations, but it does not guarantee that they will follow a standard Gaussian distribution.\nB. The bias parameter of affine layers becomes redundant if a batch normalization layer follows immediately afterward - This statement is true. Batch normalization helps in reducing the dependence on bias terms.\nC. The standard weight initialization must be changed when using Batch Normalization - This statement is not true. Batch normalization does not require a change in standard weight initialization.\nD. Batch Normalization is equivalent to Layer Normalization for convolutional neural networks - This statement is not true. Batch normalization and layer normalization are different techniques.\n\n","B","B"],["Suppose we have the following objective function: $\\argmin_{w} \\frac{1}{2} \\norm{Xw-y}^2_2 + \\frac{1}{2}\\gamma \\norm{w}^2_2$ What is the gradient of $\\frac{1}{2} \\norm{Xw-y}^2_2 + \\frac{1}{2}\\lambda \\norm{w}^2_2$ with respect to $w$?","Task Statement:\n\nFind the gradient of a given objective function with respect to a variable.\nKey Details:\n\nObjective function: $\\frac{1}{2} \\norm{Xw-y}^2_2 + \\frac{1}{2}\\gamma \\norm{w}^2_2$\nVariable: $w$\nRelevant Formulas:\n\nGradient of a function $f(w)$ with respect to $w$: $\\nabla f(w) = \\frac{\\partial f(w)}{\\partial w}$\nSteps to Solve:\n\nCalculate the gradient of the given objective function with respect to $w$.\nMissing Data:\n\nValue of $X$, $y$, and $\\gamma$ are not provided, but they are not needed to find the gradient with respect to $w$.","The gradient of a function with respect to a variable involves taking the partial derivative of the function with respect to that variable. In this case, we need to find the gradient of the given objective function with respect to $w$. To find the gradient, we will differentiate each term of the objective function with respect to $w$.\n\nGiven objective function: $\\frac{1}{2} \\norm{Xw-y}^2_2 + \\frac{1}{2}\\gamma \\norm{w}^2_2$\n\nDifferentiating the first term:\n$\\frac{1}{2} \\norm{Xw-y}^2_2 = \\frac{1}{2} (Xw-y)^\\top (Xw-y)$\nTaking the derivative with respect to $w$ gives: $X^\\top(Xw-y)$\n\nDifferentiating the second term:\n$\\frac{1}{2}\\gamma \\norm{w}^2_2 = \\frac{1}{2}\\gamma w^\\top w$\nTaking the derivative with respect to $w$ gives: $\\gamma w$\n\nCombining the derivatives of both terms, we get the gradient:\n$\\nabla_w f(w) = X^\\top(Xw-y) + \\gamma w = X^\\top X w - X^\\top y + \\gamma w$\n\n","C","C"],["Which of the following is true of a convolution kernel?","Key Details:\n\n- A convolution kernel is a matrix used for image processing.\n- It is used for operations like blurring, sharpening, edge detection.\n- The size of the kernel determines the extent of the operation on the image.\n- The values in the kernel matrix determine the effect on the image.\n- Convolution involves sliding the kernel over the image and performing calculations at each position.\n- The result is a new image with the desired effect applied.\nRelevant Formulas:\n\nN\/A\nSteps to Solve:\n\n1. Understand the concept of a convolution kernel and its purpose in image processing.\n2. Recognize that the size and values of the kernel impact the operation on the image.\n3. Remember that convolution involves sliding the kernel over the image and performing calculations.\n4. Identify the correct statement about a convolution kernel based on the given options.\nMissing Data:\n\nNone","A convolution kernel is used to apply various effects to an image by sliding the kernel over the image and performing calculations at each position. The values in the kernel matrix determine the effect on the image. In this case, we need to determine which kernel would not change the image when convolved.\n\nA. Convolving an image with $\\begin{bmatrix}1 & 0 & 0\\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{bmatrix}$ would result in the original image being shifted diagonally, so it would change the image.\nB. Convolving an image with $\\begin{bmatrix}0 & 0 & 0\\\\ 0 & 1 & 0 \\\\ 0 & 0 & 0 \\end{bmatrix}$ would result in the original image being unchanged, as it acts as an identity kernel.\nC. Convolving an image with $\\begin{bmatrix}1 & 1 & 1\\\\ 1 & 1 & 1 \\\\ 1 & 1 & 1 \\end{bmatrix}$ would blur the image, changing it.\nD. Convolving an image with $\\begin{bmatrix}0 & 0 & 0\\\\ 0 & 0 & 0 \\\\ 0 & 0 & 0 \\end{bmatrix}$ would result in a completely black image, changing it.\n\n","A","B"],["Which of the following is false?","Key Details:\n\n- Identify the false statement among the options provided\n- Multiple choice question format\n- Options to choose from\nRelevant Formulas:\n\nNone\nSteps to Solve:\n\nRead each option carefully\nDetermine which statement does not align with the given information or is incorrect\nSelect the option that is false\nMissing Data:\n\nThe specific options to choose from are not provided","A. Semantic segmentation models predict the class of each pixel, while multiclass image classifiers predict the class of the entire image. This statement is true. Semantic segmentation models do predict the class of each pixel in an image, while multiclass image classifiers predict the class of the entire image.\nB. A bounding box with an IoU (intersection over union) equal to $96\\%$ would likely be considered a true positive. This statement is true. A bounding box with a high IoU value indicates a high overlap with the ground truth bounding box, making it likely to be considered a true positive.\nC. When a predicted bounding box does not correspond to any object in the scene, it is considered a false positive. This statement is true. A false positive occurs when a predicted bounding box does not match any object in the scene, leading to an incorrect detection.\nD. A bounding box with an IoU (intersection over union) equal to $3\\%$ would likely be considered a false negative. This statement is false. A bounding box with a low IoU value indicates a low overlap with the ground truth bounding box, making it likely to be considered a false positive, not a false negative.\n\n","D","D"],["Which of the following is false?","Key Details:\n\n- A triangle has three sides\n- A square has four sides\n- A circle has three sides\n- A rectangle has four sides\n\nRelevant Formulas:\n\nNone\n\nSteps to Solve:\n\n1. Identify the shapes mentioned in the options.\n2. Determine the number of sides each shape has.\n3. Identify the shape that does not match the correct number of sides.\n4. The shape that does not match is the false statement.\n\nMissing Data:\n\nNone","1. Option A refers to a fully connected network, which is a linear combination of matrices. Matrices are linear transformations, so the composition of linear transformations is also linear.\n2. Option B refers to Leaky ReLU, which is a piecewise linear function and is convex.\n3. Option C refers to a combination of ReLUs, which are piecewise linear functions, and the combination provided is also convex.\n4. Option D refers to the loss function involving the logarithm of the sigmoid function, which is concave.\n\nTherefore, the false statement is the one that does not match the properties of the other options.\n\n","C","C"],["We are training fully connected network with two hidden layers to predict housing prices. Inputs are $100$-dimensional, and have several features such as the number of square feet, the median family income, etc. The first hidden layer has $1000$ activations. The second hidden layer has $10$ activations. The output is a scalar representing the house price. Assuming a vanilla network with affine transformations and with no batch normalization and no learnable parameters in the activation function, how many parameters does this network have?","Task Statement:\n\nCalculate the total number of parameters in a fully connected neural network with two hidden layers.\nKey Details:\n\nInput dimension: 100\nFirst hidden layer activations: 1000\nSecond hidden layer activations: 10\nOutput dimension: 1\nNo batch normalization\nNo learnable parameters in activation function\nRelevant Formulas:\n\nTotal parameters = (input dimension * first hidden layer activations) + (first hidden layer activations * second hidden layer activations) + (second hidden layer activations * output dimension)\nSteps to Solve:\n\nSubstitute the values into the formula: Total parameters = (100 * 1000) + (1000 * 10) + (10 * 1)\nCalculate the result: Total parameters = 100000 + 10000 + 10 = 110010\nMissing Data:\n\nNone","Total parameters in a fully connected neural network with two hidden layers can be calculated using the formula provided in the hint. Substituting the given values into the formula, we get:\nTotal parameters = (100 * 1000) + (1000 * 10) + (10 * 1)\nTotal parameters = 100000 + 10000 + 10 = 110010\n\n","A","A"],["Statement 1| The derivative of the sigmoid $\\sigma(x)=(1+e^{-x})^{-1}$ with respect to $x$ is equal to $\\text{Var}(B)$ where $B\\sim \\text{Bern}(\\sigma(x))$ is a Bernoulli random variable. Statement 2| Setting the bias parameters in each layer of neural network to 0 changes the bias-variance trade-off such that the model's variance increases and the model's bias decreases","Task Statement:\n\nUnderstand the relationship between the derivative of the sigmoid function, Bernoulli random variables, and the bias-variance trade-off in neural networks.\nKey Details:\n\n- Sigmoid function: $\\sigma(x) = (1 + e^{-x})^{-1}$\n- Derivative of the sigmoid function with respect to $x$ is related to $\\text{Var}(B)$\n- Bernoulli random variable: $B \\sim \\text{Bern}(\\sigma(x))$\n- Bias parameters set to 0 in neural network affect bias-variance trade-off\nRelevant Formulas:\n\n- Sigmoid function: $\\sigma(x) = (1 + e^{-x})^{-1}$\nSteps to Solve:\n\n1. Understand the relationship between the derivative of the sigmoid function and the variance of the Bernoulli random variable.\n2. Analyze how setting bias parameters to 0 in neural networks impacts the bias-variance trade-off.\nMissing Data:\n\nNone","1. The derivative of the sigmoid function $\\sigma(x) = (1 + e^{-x})^{-1}$ with respect to $x$ is given by $\\sigma'(x) = \\sigma(x)(1-\\sigma(x))$. This derivative is related to the variance of a Bernoulli random variable $B \\sim \\text{Bern}(\\sigma(x))$.\n2. Setting the bias parameters in each layer of a neural network to 0 does not directly change the bias-variance trade-off. It may affect the model's performance, but it does not necessarily increase the model's variance and decrease the model's bias.\n\n","C","C"]]}