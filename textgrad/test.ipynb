{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textgrad as tg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tg.set_backward_engine(\"gpt-4o\", override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Get an initial response from an LLM.\n",
    "model = tg.BlackboxLLM(\"gpt-3.5-turbo\")\n",
    "question_string = (\"If it takes 1 hour to dry 25 shirts under the sun, \"\n",
    "                   \"how long will it take to dry 30 shirts under the sun? \"\n",
    "                   \"Let's think step by step in order to produce the answer.\")\n",
    "\n",
    "question = tg.Variable(question_string, \n",
    "                       role_description=\"question to the LLM\", \n",
    "                       requires_grad=False)\n",
    "\n",
    "answer = model(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer.set_role_description(\"concise and accurate answer to the question\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define the loss function and the optimizer, just like in PyTorch! \n",
    "# Here, we don't have SGD, but we have TGD (Textual Gradient Descent) \n",
    "# that works with \"textual gradients\". \n",
    "optimizer = tg.TGD(parameters=[answer])\n",
    "evaluation_instruction = (f\"Here's a question: {question_string}. \" \n",
    "                           \"Evaluate any given answer to this question, \"\n",
    "                           \"be smart, logical, and very critical. \"\n",
    "                           \"Just provide concise feedback.\")\n",
    "                            \n",
    "\n",
    "# TextLoss is a natural-language specified loss function that describes \n",
    "# how we want to evaluate the reasoning.\n",
    "loss_fn = tg.TextLoss(evaluation_instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To determine how long it will take to dry 30 shirts under the sun, we assume the drying conditions (sunlight, space, airflow) remain constant. If all shirts are laid out to dry simultaneously, it will still take 1 hour to dry 30 shirts.\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Do the loss computation, backward pass, and update the punchline. \n",
    "# Exact same syntax as PyTorch!\n",
    "loss = loss_fn(answer)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
