{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "import concurrent\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "import textgrad as tg\n",
    "from textgrad.tasks import load_task\n",
    "import numpy as np\n",
    "import random\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_sample(item, eval_fn, model):\n",
    "    \"\"\"\n",
    "    This function allows us to evaluate if an answer to a question in the prompt is a good answer.\n",
    "\n",
    "    \"\"\"\n",
    "    x, y = item\n",
    "    x = tg.Variable(x, requires_grad=False, role_description=\"query to the language model\")\n",
    "    y = tg.Variable(y, requires_grad=False, role_description=\"correct answer for the query\")\n",
    "    response = model(x)\n",
    "    try:\n",
    "        eval_output_variable = eval_fn(inputs=dict(prediction=response, ground_truth_answer=y))\n",
    "        return int(eval_output_variable.value)\n",
    "    except:\n",
    "        eval_output_variable = eval_fn([x, y, response])\n",
    "        eval_output_parsed = eval_fn.parse_output(eval_output_variable)\n",
    "        return int(eval_output_parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_dataset(test_set, eval_fn, model, max_samples: int=None):\n",
    "    if max_samples is None:\n",
    "        max_samples = len(test_set)\n",
    "    accuracy_list = []\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n",
    "        futures = []\n",
    "        for _, sample in enumerate(test_set):\n",
    "            \n",
    "            future = executor.submit(eval_sample, sample, eval_fn, model)\n",
    "            futures.append(future)\n",
    "            if len(futures) >= max_samples:\n",
    "                break\n",
    "        tqdm_loader = tqdm(concurrent.futures.as_completed(futures), total=len(futures), position=0)\n",
    "        for future in tqdm_loader:\n",
    "            acc_item = future.result()\n",
    "            accuracy_list.append(acc_item)\n",
    "            tqdm_loader.set_description(f\"Accuracy: {np.mean(accuracy_list)}\")\n",
    "    return accuracy_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_validation_revert(system_prompt: tg.Variable, system_prompt2: tg.Variable, results, model, eval_fn, val_set):\n",
    "    val_performance = np.mean(eval_dataset(val_set, eval_fn, model))\n",
    "    previous_performance = np.mean(results[\"validation_acc\"][-1])\n",
    "    print(\"val_performance: \", val_performance)\n",
    "    print(\"previous_performance: \", previous_performance)\n",
    "    previous_prompt = results[\"prompt\"][-1]\n",
    "    previous_prompt2 = results[\"prompt2\"][-1]\n",
    "    \n",
    "    if val_performance < previous_performance:\n",
    "        print(f\"rejected prompt: {system_prompt.value}\")\n",
    "        system_prompt.set_value(previous_prompt)\n",
    "        # system_prompt2.set_value(previous_prompt2)\n",
    "        val_performance = previous_performance\n",
    "\n",
    "    results[\"validation_acc\"].append(val_performance)\n",
    "    results[\"prompt\"].append(system_prompt.value)\n",
    "    results[\"prompt2\"].append(system_prompt2.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Val/Test Set Lengths:  50 100 100\n"
     ]
    }
   ],
   "source": [
    "set_seed(12)\n",
    "llm_api_eval = tg.get_engine(engine_name=\"gpt-3.5-turbo-0125\")\n",
    "llm_api_test = tg.get_engine(engine_name=\"gpt-3.5-turbo-0125\")\n",
    "tg.set_backward_engine(llm_api_eval, override=True)\n",
    "\n",
    "# Load the data and the evaluation function\n",
    "train_set, val_set, test_set, eval_fn = load_task(\"BBH_object_counting\", evaluation_api=llm_api_eval)\n",
    "print(\"Train/Val/Test Set Lengths: \", len(train_set), len(val_set), len(test_set))\n",
    "STARTING_SYSTEM_PROMPT = train_set.get_task_description()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You will answer a reasoning question. Think step by step. The last line of your response should be of the following format: 'Answer: $VALUE' where VALUE is a numerical value.\n"
     ]
    }
   ],
   "source": [
    "print(STARTING_SYSTEM_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.79: 100%|██████████| 100/100 [00:00<00:00, 1631.16it/s]  \n",
      "Accuracy: 0.7: 100%|██████████| 100/100 [00:00<00:00, 1849.38it/s]    \n"
     ]
    }
   ],
   "source": [
    "train_loader = tg.tasks.DataLoader(train_set, batch_size=3, shuffle=True)\n",
    "\n",
    "\n",
    "# Testing the 0-shot performance of the evaluation engine\n",
    "system_prompt = tg.Variable(STARTING_SYSTEM_PROMPT, \n",
    "                            requires_grad=True, \n",
    "                            role_description=\"system prompt to the language model\")\n",
    "model_evaluation = tg.BlackboxLLM(llm_api_eval, system_prompt)\n",
    "\n",
    "system_prompt = tg.Variable(STARTING_SYSTEM_PROMPT, \n",
    "                            requires_grad=True,\n",
    "                            role_description=\"structured system prompt to a somewhat capable language model that specifies the behavior and strategies for the QA task\")\n",
    "model1 = tg.BlackboxLLM(llm_api_test, system_prompt)\n",
    "\n",
    "system_prompt2 = tg.Variable(\"return the same thing as the input.\", \n",
    "                            requires_grad=True,\n",
    "                            role_description=\"return the same thing as the input.\")\n",
    "model2 = tg.BlackboxLLM(llm_api_test, system_prompt2)\n",
    "\n",
    "def model(input):\n",
    "    input1 = model1(input)\n",
    "    return model2(input1)\n",
    "\n",
    "optimizer = tg.TextualGradientDescent(engine=llm_api_eval, parameters=[system_prompt, system_prompt2])\n",
    "\n",
    "results = {\"test_acc\": [], \"prompt\": [], \"validation_acc\": [], \"prompt2\": []}\n",
    "results[\"test_acc\"].append(eval_dataset(test_set, eval_fn, model))\n",
    "results[\"validation_acc\"].append(eval_dataset(val_set, eval_fn, model))\n",
    "results[\"prompt\"].append(system_prompt.get_value())\n",
    "results[\"prompt2\"].append(system_prompt2.get_value())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training step 0. Epoch 0: : 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:  I have a cauliflower, a stalk of celery, a cabbage, and a garlic. How many vegetables do I have?\n",
      "x:  I have a trumpet, four trombones, an accordion, a clarinet, a violin, and a drum. How many musical instruments do I have?\n",
      "x:  I have a blackberry, a peach, a nectarine, a plum, a raspberry, an orange, a strawberry, a banana, two apples, and four grapes. How many fruits do I have?\n",
      "total_loss:  1\n",
      "1\n",
      "1\n",
      "system_prompt.grad:  You will answer a reasoning question. Think step by step. The last line of your response should be of the following format: 'Answer: $VALUE' where VALUE is a numerical value.\n",
      "system_prompt:  Calculate the total number of vegetables by counting each individual vegetable. Ensure to provide a step-by-step breakdown of your reasoning process. End your response with the format: 'Answer: $VALUE' where VALUE is a numerical value.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.55: 100%|██████████| 100/100 [02:00<00:00,  1.20s/it]              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_performance:  0.55\n",
      "previous_performance:  0.7\n",
      "rejected prompt: Calculate the total number of vegetables by counting each individual vegetable. Ensure to provide a step-by-step breakdown of your reasoning process. End your response with the format: 'Answer: $VALUE' where VALUE is a numerical value.\n",
      "sys prompt:  You will answer a reasoning question. Think step by step. The last line of your response should be of the following format: 'Answer: $VALUE' where VALUE is a numerical value.\n",
      "sys prompt2:  Enhance the response based on the input text.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.48: 100%|██████████| 100/100 [00:42<00:00,  2.37it/s]              \n",
      "Training step 1. Epoch 0: : 1it [03:40, 220.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:  I have a piano, and a trombone. How many musical instruments do I have?\n",
      "x:  I have a bed, a fridge, a lamp, a toaster, four chairs, and a table. How many objects do I have?\n",
      "x:  I have a piano, an accordion, three trombones, five clarinets, a violin, a drum, a trumpet, and three flutes. How many musical instruments do I have?\n",
      "total_loss:  0\n",
      "0\n",
      "1\n",
      "system_prompt.grad:  You will answer a reasoning question. Think step by step. The last line of your response should be of the following format: 'Answer: $VALUE' where VALUE is a numerical value.\n",
      "system_prompt:  Provide a clear and precise response to the following question by calculating the total number of objects. Break down the problem by listing each object before determining the final count. Conclude your answer in the following format: 'Answer: $VALUE' where VALUE is the numerical result.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.37: 100%|██████████| 100/100 [01:30<00:00,  1.10it/s]              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_performance:  0.37\n",
      "previous_performance:  0.7\n",
      "rejected prompt: Provide a clear and precise response to the following question by calculating the total number of objects. Break down the problem by listing each object before determining the final count. Conclude your answer in the following format: 'Answer: $VALUE' where VALUE is the numerical result.\n",
      "sys prompt:  You will answer a reasoning question. Think step by step. The last line of your response should be of the following format: 'Answer: $VALUE' where VALUE is a numerical value.\n",
      "sys prompt2:  Ensure the response states the total number of musical instruments calculated clearly and precisely.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.34: 100%|██████████| 100/100 [00:36<00:00,  2.72it/s]              \n",
      "Training step 2. Epoch 0: : 2it [06:43, 198.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:  I have a stove, a bed, a lamp, three microwaves, a chair, a toaster, a table, two cars, a fridge, and an oven. How many objects do I have?\n",
      "x:  I have a flute, a trumpet, three accordions, three violins, a drum, three clarinets, and a trombone. How many musical instruments do I have?\n",
      "x:  I have a piano, a trombone, a clarinet, a goat, an accordion, and a trumpet. How many musical instruments do I have?\n",
      "total_loss:  0\n",
      "1\n",
      "1\n",
      "system_prompt.grad:  You will answer a reasoning question. Think step by step. The last line of your response should be of the following format: 'Answer: $VALUE' where VALUE is a numerical value.\n",
      "system_prompt:  You will answer a reasoning question involving counting musical instruments. Follow the steps to calculate the total number of instruments. Ensure to accurately sum up numerical quantities and provide a clear and concise response. Your final answer should be presented in a straightforward manner without unnecessary details. Before finalizing your answer, double-check the accuracy of your calculation and ensure it aligns with the provided format. The last line of your response should be of the following format: 'Answer: $VALUE' where VALUE is a numerical value.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.39: 100%|██████████| 100/100 [00:56<00:00,  1.78it/s]              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_performance:  0.39\n",
      "previous_performance:  0.7\n",
      "rejected prompt: You will answer a reasoning question involving counting musical instruments. Follow the steps to calculate the total number of instruments. Ensure to accurately sum up numerical quantities and provide a clear and concise response. Your final answer should be presented in a straightforward manner without unnecessary details. Before finalizing your answer, double-check the accuracy of your calculation and ensure it aligns with the provided format. The last line of your response should be of the following format: 'Answer: $VALUE' where VALUE is a numerical value.\n",
      "sys prompt:  You will answer a reasoning question. Think step by step. The last line of your response should be of the following format: 'Answer: $VALUE' where VALUE is a numerical value.\n",
      "sys prompt2:  Ensure the response states the total number of musical instruments calculated clearly and precisely based on the provided list of quantities for each instrument.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.38: 100%|██████████| 100/100 [00:43<00:00,  2.32it/s]              \n",
      "Training step 3. Epoch 0: : 3it [09:29, 183.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:  I have a yam, a cauliflower, a garlic, two lettuce heads, a head of broccoli, a potato, a stalk of celery, and an onion. How many vegetables do I have?\n",
      "x:  I have three fridges, a bed, and five stoves. How many objects do I have?\n",
      "x:  I have a raspberry, a grape, and an orange. How many fruits do I have?\n",
      "total_loss:  0\n",
      "0\n",
      "1\n",
      "system_prompt.grad:  You will answer a reasoning question. Think step by step. The last line of your response should be of the following format: 'Answer: $VALUE' where VALUE is a numerical value.\n",
      "system_prompt:  You will answer a reasoning question by calculating the total number of musical instruments. Provide a step-by-step explanation of your reasoning process. Your final response should be in the following format: 'Answer: $VALUE' where VALUE is a numerical value representing the total count of musical instruments.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.23: 100%|██████████| 100/100 [02:17<00:00,  1.37s/it]              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_performance:  0.23\n",
      "previous_performance:  0.7\n",
      "rejected prompt: You will answer a reasoning question by calculating the total number of musical instruments. Provide a step-by-step explanation of your reasoning process. Your final response should be in the following format: 'Answer: $VALUE' where VALUE is a numerical value representing the total count of musical instruments.\n",
      "sys prompt:  You will answer a reasoning question. Think step by step. The last line of your response should be of the following format: 'Answer: $VALUE' where VALUE is a numerical value.\n",
      "sys prompt2:  Ensure the response provides the total count of musical instruments accurately based on the quantities provided for each instrument.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.29: 100%|██████████| 100/100 [00:51<00:00,  1.95it/s]              \n",
      "Training step 3. Epoch 0: : 3it [13:49, 276.59s/it]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1):\n",
    "    for steps, (batch_x, batch_y) in enumerate((pbar := tqdm(train_loader, position=0))):\n",
    "        pbar.set_description(f\"Training step {steps}. Epoch {epoch}\")\n",
    "        optimizer.zero_grad()\n",
    "        losses = []\n",
    "        for (x, y) in zip(batch_x, batch_y):\n",
    "            print(\"x: \", x)\n",
    "            x = tg.Variable(x, requires_grad=False, role_description=\"query to the language model\")\n",
    "            y = tg.Variable(y, requires_grad=False, role_description=\"correct answer for the query\")\n",
    "            response = model(x)\n",
    "            try:\n",
    "                eval_output_variable = eval_fn(inputs=dict(prediction=response, ground_truth_answer=y))\n",
    "            except:\n",
    "                eval_output_variable = eval_fn([x, y, response])\n",
    "            losses.append(eval_output_variable)\n",
    "        total_loss = tg.sum(losses)\n",
    "        print(\"total_loss: \", total_loss)\n",
    "        total_loss.backward()\n",
    "        print(\"system_prompt.grad: \", system_prompt)\n",
    "        optimizer.step()\n",
    "\n",
    "        print(\"system_prompt: \", system_prompt)\n",
    "        run_validation_revert(system_prompt, system_prompt2, results, model, eval_fn, val_set)\n",
    "        \n",
    "        print(\"sys prompt: \", system_prompt)\n",
    "        print(\"sys prompt2: \", system_prompt2)\n",
    "        test_acc = eval_dataset(test_set, eval_fn, model)\n",
    "        results[\"test_acc\"].append(test_acc)\n",
    "        results[\"prompt\"].append(system_prompt.get_value())\n",
    "        results[\"prompt2\"].append(system_prompt2.get_value())\n",
    "        if steps == 3:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"You will answer a reasoning question. Think step by step. The last line of your response should be of the following format: 'Answer: $VALUE' where VALUE is a numerical value.\",\n",
       " \"You will answer a reasoning question. Think step by step. The last line of your response should be of the following format: 'Answer: $VALUE' where VALUE is a numerical value.\",\n",
       " \"You will answer a reasoning question. Think step by step. The last line of your response should be of the following format: 'Answer: $VALUE' where VALUE is a numerical value.\",\n",
       " \"You will answer a reasoning question. Think step by step. The last line of your response should be of the following format: 'Answer: $VALUE' where VALUE is a numerical value.\",\n",
       " \"You will answer a reasoning question. Think step by step. The last line of your response should be of the following format: 'Answer: $VALUE' where VALUE is a numerical value.\",\n",
       " \"You will answer a reasoning question. Think step by step. The last line of your response should be of the following format: 'Answer: $VALUE' where VALUE is a numerical value.\",\n",
       " \"You will answer a reasoning question. Think step by step. The last line of your response should be of the following format: 'Answer: $VALUE' where VALUE is a numerical value.\",\n",
       " \"You will answer a reasoning question. Think step by step. The last line of your response should be of the following format: 'Answer: $VALUE' where VALUE is a numerical value.\",\n",
       " \"You will answer a reasoning question. Think step by step. The last line of your response should be of the following format: 'Answer: $VALUE' where VALUE is a numerical value.\"]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"prompt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['return the same thing as the input.',\n",
       " 'Enhance the response based on the input text.',\n",
       " 'Enhance the response based on the input text.',\n",
       " 'Ensure the response states the total number of musical instruments calculated clearly and precisely.',\n",
       " 'Ensure the response states the total number of musical instruments calculated clearly and precisely.',\n",
       " 'Ensure the response states the total number of musical instruments calculated clearly and precisely based on the provided list of quantities for each instrument.',\n",
       " 'Ensure the response states the total number of musical instruments calculated clearly and precisely based on the provided list of quantities for each instrument.',\n",
       " 'Ensure the response provides the total count of musical instruments accurately based on the quantities provided for each instrument.',\n",
       " 'Ensure the response provides the total count of musical instruments accurately based on the quantities provided for each instrument.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"prompt2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
